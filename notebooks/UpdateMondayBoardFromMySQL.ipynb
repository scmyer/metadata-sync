{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook will develp the SOP for updating the Monday.com studies board consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\"/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202407/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_values(df:pd.DataFrame, col_name:str='appl_id'):\n",
    "    if col_name in df.columns:\n",
    "        return df[ ~pd.isna(df[col_name])][col_name].drop_duplicates()\n",
    "    return None\n",
    "\n",
    "def get_na_count(df:pd.DataFrame, col_name:str='appl_id'):\n",
    "    if col_name in df.columns:\n",
    "        return len(df[pd.isna(df[col_name])])\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1477\n",
      "Index(['appl_id', 'xstudy_id', 'study_most_recent_appl', 'study_hdp_id',\n",
      "       'study_hdp_id_appl'],\n",
      "      dtype='object')\n",
      "appl_id                   object\n",
      "xstudy_id                 object\n",
      "study_most_recent_appl    object\n",
      "study_hdp_id              object\n",
      "study_hdp_id_appl         object\n",
      "dtype: object\n",
      "Number of distinct values in --appl_id--: 1468\n",
      "---- NA count: 0\n",
      "Number of funky looking appl_ids: 0\n",
      "Number of distinct values in --xstudy_id--: 1200\n",
      "---- NA count: 0\n",
      "Number of distinct values in --study_most_recent_appl--: 1191\n",
      "---- NA count: 0\n",
      "Number of funky looking appl_ids: 0\n",
      "Number of distinct values in --study_hdp_id--: 1162\n",
      "---- NA count: 51\n",
      " Number of funky looking HDPIDs: 0\n",
      "Number of distinct values in --study_hdp_id_appl--: 1153\n",
      "---- NA count: 51\n",
      "Number of funky looking appl_ids: 0\n"
     ]
    }
   ],
   "source": [
    "gt_file = pd.read_csv(input_dir/\"study_lookup_table.csv\", dtype=str)\n",
    "gt_file.replace(\"0\", np.NaN, inplace=True)\n",
    "\n",
    "print(len(gt_file))\n",
    "print(gt_file.columns)\n",
    "print(gt_file.dtypes)\n",
    "### QC the file:\n",
    "for k in gt_file.columns:\n",
    "    print(f\"Number of distinct values in --{k}--: {len(get_unique_values(gt_file, k))}\")\n",
    "    print(f\"---- NA count: {get_na_count(gt_file, k)}\")\n",
    "    ## Look for patterns?\n",
    "    if 'appl' in k:\n",
    "        d = gt_file[[ (not pd.isna(l)) and (not l.isdigit()) for l in gt_file[k] ]]\n",
    "        print(f\"Number of funky looking appl_ids: {len(d)}\")\n",
    "    elif k == 'study_hdp_id':\n",
    "        d = gt_file[ [ (not pd.isna(l)) and (re.match(r'HDP[\\d]+', l) is None) for l in gt_file[k]]]\n",
    "        print(f\" Number of funky looking HDPIDs: {len(d)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PosixPath('/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202407/HEAL_Studies_Studies_under_investigation_1723180673.xlsx'), PosixPath('/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202407/HEAL_Studies_Studies_never_added_to_the_Platform_legacy_1723180718.xlsx'), PosixPath('/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202407/HEAL_Studies_CTN_Protocols_1723180574.xlsx'), PosixPath('/Users/hinashah/Documents/HEAL/MondayFolderUpdate_202407/HEAL_Studies_HEAL_Studies_in_the_Platform_1723180621.xlsx')]\n",
      "8\n",
      "45\n",
      "84\n",
      "1244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/3039130219.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  monday_board = pd.concat([monday_board, tmp_df])\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/3039130219.py:18: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  monday_board = pd.concat([monday_board, tmp_df])\n"
     ]
    }
   ],
   "source": [
    "## Import Monday Board \n",
    "## TODO: change to read in all groups\n",
    "board_files_list = list(input_dir.glob(\"HEAL_Studies_*.xlsx\"))\n",
    "print(board_files_list)\n",
    "monday_board = pd.DataFrame()\n",
    "for file_path in board_files_list:\n",
    "    tmp_df = pd.read_excel(file_path, skiprows=4, dtype={\"Most Recent Appl_ID\":str, \"Name\":str}, skipfooter=1)\n",
    "    group_name = ' '.join(file_path.name.split('_')[2:-1])\n",
    "    if group_name == 'Studies never added to the Platform legacy':\n",
    "        study_type = 'APPLIDONLY'\n",
    "    elif group_name == 'HEAL Studies in the Platform':\n",
    "        study_type = \"HDP\"\n",
    "    elif group_name == \"CTN Protocols\":\n",
    "        study_type == \"CTN\"\n",
    "    else:\n",
    "        study_type = \"Unknown\"  \n",
    "    tmp_df['study_type'] = [study_type]*len(tmp_df)\n",
    "    monday_board = pd.concat([monday_board, tmp_df])\n",
    "    print(len(monday_board))\n",
    "\n",
    "# monday_board = pd.read_excel(input_dir/\"HEAL_Studies_1719341536.xlsx\", skiprows=4, dtype={\"Most Recent Appl_ID\":str}, skipfooter=1)\n",
    "# print(monday_board[\"Name\"].describe())\n",
    "# print(monday_board.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number records from Monday already in lookup table: 1160\n",
      "Number records from Monday that are not in lookup table: 84\n",
      "Number records from l0ookup that are not in Monday: 40\n"
     ]
    }
   ],
   "source": [
    "### Steps for updating Monday board:\n",
    "\n",
    "## From Study lookup table, get unique set of most_recent_appl, study_hdp_id, and study_hdp_id_appl\n",
    "lookup_fields = gt_file[['study_hdp_id', 'study_most_recent_appl', 'study_hdp_id_appl']].copy(deep=True).drop_duplicates()\n",
    "## Create a column \"Name\" or \"Key\" that will either have study_hdp_id OR most_recent_appl when study_hdp_id is empty\n",
    "lookup_fields['key'] = [m if pd.isna(h) else h for (h, m) in lookup_fields[['study_hdp_id', 'study_most_recent_appl']].values ]\n",
    "\n",
    "### A few checks:\n",
    "## How many of the \"keys\" from Monday board are in lookup fields?\n",
    "print(f\"Number records from Monday already in lookup table: {len(monday_board[monday_board.Name.isin(lookup_fields.key)])}\")\n",
    "## How many of the keys from MOnday board are not there in looup fields\n",
    "mondayboard_missingin_looup = monday_board[~monday_board.Name.isin(lookup_fields.key)]\n",
    "print(f\"Number records from Monday that are not in lookup table: {len(mondayboard_missingin_looup)}\")\n",
    "## How many of the keys from lookup fields are not there in Monday??\n",
    "lookup_missingin_mondayboard = lookup_fields[~lookup_fields.key.isin(monday_board.Name)]\n",
    "print(f\"Number records from l0ookup that are not in Monday: {len(lookup_missingin_mondayboard)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Most Recent Appl_ID</th>\n",
       "      <th>HDP appl_ID</th>\n",
       "      <th>Project #</th>\n",
       "      <th>Archived</th>\n",
       "      <th>HEAL-Related</th>\n",
       "      <th>Research Focus</th>\n",
       "      <th>Research Program</th>\n",
       "      <th>Title</th>\n",
       "      <th>Contact PI</th>\n",
       "      <th>...</th>\n",
       "      <th>Repo per Platform</th>\n",
       "      <th>Platform Reg Time</th>\n",
       "      <th>CEDAR Form %</th>\n",
       "      <th>Repo Mapping</th>\n",
       "      <th>repo_22_2</th>\n",
       "      <th>repo_22_3</th>\n",
       "      <th>Creation Log</th>\n",
       "      <th>study_type</th>\n",
       "      <th>link to Draft Data Dictionary Tracker</th>\n",
       "      <th>link to Draft Data Dictionary Tracker.1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HDP01285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0130</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:05 PM</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HDP01286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0133</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:05 PM</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HDP01287</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0095-A-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:05 PM</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN0095A2-Data-Dictionary.xlsx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HDP01288</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0093</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NIDA Data Share</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:05 PM</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN0093-DataDictionary.xlx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HDP01289</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:05 PM</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>HDP01319</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:01 PM</td>\n",
       "      <td>APPLIDONLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>HDP01320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:01 PM</td>\n",
       "      <td>APPLIDONLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>HDP01321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:01 PM</td>\n",
       "      <td>APPLIDONLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>HDP01322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0084-A-2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:01 PM</td>\n",
       "      <td>APPLIDONLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>HDP01323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CTN-0094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaT</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hina Shah Jun 26, 2024 2:01 PM</td>\n",
       "      <td>APPLIDONLY</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Most Recent Appl_ID  HDP appl_ID     Project # Archived  \\\n",
       "0   HDP01285                 NaN          NaN      CTN-0130      NaN   \n",
       "1   HDP01286                 NaN          NaN      CTN-0133      NaN   \n",
       "2   HDP01287                 NaN          NaN  CTN-0095-A-2      NaN   \n",
       "3   HDP01288                 NaN          NaN      CTN-0093      NaN   \n",
       "4   HDP01289                 NaN          NaN      CTN-0147      NaN   \n",
       "..       ...                 ...          ...           ...      ...   \n",
       "34  HDP01319                 NaN          NaN      CTN-0097      NaN   \n",
       "35  HDP01320                 NaN          NaN      CTN-0110      NaN   \n",
       "36  HDP01321                 NaN          NaN      CTN-0096      NaN   \n",
       "37  HDP01322                 NaN          NaN  CTN-0084-A-2      NaN   \n",
       "38  HDP01323                 NaN          NaN      CTN-0094      NaN   \n",
       "\n",
       "   HEAL-Related Research Focus Research Program Title Contact PI  ...  \\\n",
       "0           NaN            NaN              NaN   NaN        NaN  ...   \n",
       "1           NaN            NaN              NaN   NaN        NaN  ...   \n",
       "2           NaN            NaN              NaN   NaN        NaN  ...   \n",
       "3           NaN            NaN              NaN   NaN        NaN  ...   \n",
       "4           NaN            NaN              NaN   NaN        NaN  ...   \n",
       "..          ...            ...              ...   ...        ...  ...   \n",
       "34          NaN            NaN              NaN   NaN        NaN  ...   \n",
       "35          NaN            NaN              NaN   NaN        NaN  ...   \n",
       "36          NaN            NaN              NaN   NaN        NaN  ...   \n",
       "37          NaN            NaN              NaN   NaN        NaN  ...   \n",
       "38          NaN            NaN              NaN   NaN        NaN  ...   \n",
       "\n",
       "   Repo per Platform Platform Reg Time CEDAR Form % Repo Mapping repo_22_2  \\\n",
       "0                NaN               NaT          0.0          NaN       NaN   \n",
       "1                NaN               NaT          0.0          NaN       NaN   \n",
       "2    NIDA Data Share               NaT          0.0          NaN       NaN   \n",
       "3    NIDA Data Share               NaT          0.0          NaN       NaN   \n",
       "4                NaN               NaT          0.0          NaN       NaN   \n",
       "..               ...               ...          ...          ...       ...   \n",
       "34               NaN               NaT          0.0          NaN       NaN   \n",
       "35               NaN               NaT          0.0          NaN       NaN   \n",
       "36               NaN               NaT          0.0          NaN       NaN   \n",
       "37               NaN               NaT          0.0          NaN       NaN   \n",
       "38               NaN               NaT          0.0          NaN       NaN   \n",
       "\n",
       "   repo_22_3                    Creation Log  study_type  \\\n",
       "0        NaN  Hina Shah Jun 26, 2024 2:05 PM     Unknown   \n",
       "1        NaN  Hina Shah Jun 26, 2024 2:05 PM     Unknown   \n",
       "2        NaN  Hina Shah Jun 26, 2024 2:05 PM     Unknown   \n",
       "3        NaN  Hina Shah Jun 26, 2024 2:05 PM     Unknown   \n",
       "4        NaN  Hina Shah Jun 26, 2024 2:05 PM     Unknown   \n",
       "..       ...                             ...         ...   \n",
       "34       NaN  Hina Shah Jun 26, 2024 2:01 PM  APPLIDONLY   \n",
       "35       NaN  Hina Shah Jun 26, 2024 2:01 PM  APPLIDONLY   \n",
       "36       NaN  Hina Shah Jun 26, 2024 2:01 PM  APPLIDONLY   \n",
       "37       NaN  Hina Shah Jun 26, 2024 2:01 PM  APPLIDONLY   \n",
       "38       NaN  Hina Shah Jun 26, 2024 2:01 PM  APPLIDONLY   \n",
       "\n",
       "    link to Draft Data Dictionary Tracker  \\\n",
       "0                                     NaN   \n",
       "1                                     NaN   \n",
       "2                                     NaN   \n",
       "3                                     NaN   \n",
       "4                                     NaN   \n",
       "..                                    ...   \n",
       "34                                    NaN   \n",
       "35                                    NaN   \n",
       "36                                    NaN   \n",
       "37                                    NaN   \n",
       "38                                    NaN   \n",
       "\n",
       "    link to Draft Data Dictionary Tracker.1  \n",
       "0                                       NaN  \n",
       "1                                       NaN  \n",
       "2            CTN0095A2-Data-Dictionary.xlsx  \n",
       "3                CTN0093-DataDictionary.xlx  \n",
       "4                                       NaN  \n",
       "..                                      ...  \n",
       "34                                      NaN  \n",
       "35                                      NaN  \n",
       "36                                      NaN  \n",
       "37                                      NaN  \n",
       "38                                      NaN  \n",
       "\n",
       "[84 rows x 40 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mondayboard_missingin_looup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awards table has: 1618 entries, with 1618 appl_ids\n",
      "Reporter table has: 1617 entries, with 1617 appl_ids\n",
      "Platform generated table has: 1322 entries, with 1313 appl_ids\n",
      "Platform table has 1313 unique HDP IDs\n",
      "Repo mapping table has: 1323 entrie, with 1323 appl_ids\n",
      "Repo mapping table has: 1059 entrie, with 1059 appl_ids\n",
      "Research Network table has: 1662 entrie, with 1662 appl_ids\n"
     ]
    }
   ],
   "source": [
    "# Get rest of the tables\n",
    "convert_dict = {'appl_id':str}\n",
    "\n",
    "awards_df = pd.read_csv(input_dir/\"awards.csv\", low_memory=False, dtype=convert_dict)\n",
    "awards_df = awards_df.dropna(how='all')\n",
    "print(f\"Awards table has: {len(awards_df)} entries, with {len(get_unique_values(awards_df))} appl_ids\")\n",
    "reporter_df = pd.read_csv(input_dir/\"reporter.csv\", low_memory=False, dtype=convert_dict)\n",
    "reporter_df = reporter_df.dropna(how='all')\n",
    "print(f\"Reporter table has: {len(reporter_df)} entries, with {len(get_unique_values(reporter_df))} appl_ids\")\n",
    "progress_tracker_df = pd.read_csv(input_dir/\"progress_tracker.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Platform generated table has: {len(progress_tracker_df)} entries, with {len(get_unique_values(progress_tracker_df))} appl_ids\")\n",
    "print(f\"Platform table has {len(get_unique_values(progress_tracker_df))} unique HDP IDs\")\n",
    "repo_maping_df = pd.read_csv(input_dir/\"repo_mapping.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Repo mapping table has: {len(repo_maping_df)} entrie, with {len(get_unique_values(repo_maping_df))} appl_ids\")\n",
    "pi_emails_df = pd.read_csv(input_dir/\"pi_emails.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Repo mapping table has: {len(pi_emails_df)} entrie, with {len(get_unique_values(pi_emails_df))} appl_ids\")\n",
    "resnet_df = pd.read_csv(input_dir/\"research_networks.csv\", low_memory=False, dtype=convert_dict)\n",
    "print(f\"Research Network table has: {len(resnet_df)} entrie, with {len(get_unique_values(resnet_df))} appl_ids\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1468\n",
      "     study_most_recent_appl                   pi_email_latest\n",
      "1                   9755001                 kwatkins@rand.org\n",
      "2                   9850412                   damico@rand.org\n",
      "4                  10478911                 LYNN.DEBAR@KP.ORG\n",
      "8                  10468778          cheville.andrea@mayo.edu\n",
      "11                 10054792                   xcao11@jhmi.edu\n",
      "...                     ...                               ...\n",
      "1455               10167785               bahmedani@yahoo.com\n",
      "1456               10331849                  tbrocki1@JHU.EDU\n",
      "1458               10197811                  kzivin@UMICH.EDU\n",
      "1459               10197809            Gregory.E.Simon@kp.org\n",
      "1461                9823898  d-mencihella@md.northwestern.edu\n",
      "\n",
      "[876 rows x 2 columns]\n",
      "count    875.000000\n",
      "mean       1.001143\n",
      "std        0.033806\n",
      "min        1.000000\n",
      "25%        1.000000\n",
      "50%        1.000000\n",
      "75%        1.000000\n",
      "max        2.000000\n",
      "dtype: float64\n",
      "1468\n",
      "     study_most_recent_appl                  pi_email\n",
      "0                   9860408                          \n",
      "1                   9755001         kwatkins@rand.org\n",
      "2                   9850412           damico@rand.org\n",
      "4                  10478911         LYNN.DEBAR@KP.ORG\n",
      "8                  10468778  cheville.andrea@mayo.edu\n",
      "...                     ...                       ...\n",
      "1463               10022491                          \n",
      "1464               10493291                          \n",
      "1465                9555046                          \n",
      "1466                9775470                          \n",
      "1467               10589995                          \n",
      "\n",
      "[1191 rows x 2 columns]\n",
      "     study_most_recent_appl                  pi_email  \\\n",
      "0                   9860408                             \n",
      "1                   9755001         kwatkins@rand.org   \n",
      "2                   9850412           damico@rand.org   \n",
      "3                  10478911         LYNN.DEBAR@KP.ORG   \n",
      "4                  10468778  cheville.andrea@mayo.edu   \n",
      "...                     ...                       ...   \n",
      "1186               10022491                             \n",
      "1187               10493291                             \n",
      "1188                9555046                             \n",
      "1189                9775470                             \n",
      "1190               10589995                             \n",
      "\n",
      "                 Contact Email          pi_email_updated  \n",
      "0                                                         \n",
      "1            kwatkins@rand.org         kwatkins@rand.org  \n",
      "2              damico@rand.org           damico@rand.org  \n",
      "3            LYNN.DEBAR@KP.ORG         LYNN.DEBAR@KP.ORG  \n",
      "4     cheville.andrea@mayo.edu  cheville.andrea@mayo.edu  \n",
      "...                        ...                       ...  \n",
      "1186                         -                            \n",
      "1187                         -                            \n",
      "1188                         -                            \n",
      "1189                         -                            \n",
      "1190                         -                            \n",
      "\n",
      "[1191 rows x 4 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/1544714968.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  appl_ids_emails['pi_email'].fillna('', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/1544714968.py:25: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  pi_emails_df_updated_monday['Contact Email'].replace('-', '', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/1544714968.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  pi_emails_df_updated_monday['Contact Email'].fillna('-', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Manipulate emails to carry forward emails from a previous appl_id to the most recent one according to the lookup table and email table\n",
    "appl_ids = gt_file[['appl_id', 'study_most_recent_appl']].drop_duplicates()\n",
    "print(len(appl_ids))\n",
    "appl_ids_emails = pd.merge(appl_ids, pi_emails_df, how='left', on='appl_id')\n",
    "\n",
    "most_recent_emails = appl_ids_emails[ ~pd.isna(appl_ids_emails.pi_email)][['study_most_recent_appl', 'pi_email']].drop_duplicates()\n",
    "most_recent_emails.rename(columns={'pi_email':'pi_email_latest'}, inplace=True)\n",
    "print(most_recent_emails)\n",
    "email_counts = most_recent_emails.groupby('study_most_recent_appl').size()\n",
    "appl_ids_counts = appl_ids_emails.groupby('study_most_recent_appl').size()\n",
    "\n",
    "print(email_counts.describe())\n",
    "appl_ids_emails['email_count'] = [email_counts[k] if k in email_counts else 0 for k in appl_ids_emails['study_most_recent_appl']]\n",
    "appl_ids_emails['applid_count'] = [appl_ids_counts[k] if k in appl_ids_counts else 0 for k in appl_ids_emails['study_most_recent_appl']]\n",
    "appl_ids_emails['pi_email'].fillna('', inplace=True)\n",
    "appl_ids_emails['keep'] = [1 if (c==0 or (c==1 and len(e)>0) or (c>1 and a==m)) else 0 for (c,a,m,e) in appl_ids_emails[['email_count', 'appl_id', 'study_most_recent_appl', 'pi_email' ]].values]\n",
    "print(len(appl_ids_emails))\n",
    "\n",
    "pi_emails_df_updated = appl_ids_emails[appl_ids_emails['keep']==1][['study_most_recent_appl', 'pi_email']].drop_duplicates()\n",
    "pi_emails_df_updated['pi_email'] = [k.strip() for k in pi_emails_df_updated['pi_email']]\n",
    "print(pi_emails_df_updated)\n",
    "\n",
    "## Get Monday board emails, and fill in any that are different from mysql..\n",
    "pi_emails_df_updated_monday = pd.merge(pi_emails_df_updated, monday_board[['Most Recent Appl_ID', 'Contact Email']].drop_duplicates(), how='left', left_on='study_most_recent_appl', right_on='Most Recent Appl_ID').drop(columns='Most Recent Appl_ID')\n",
    "pi_emails_df_updated_monday['Contact Email'].replace('-', '', inplace=True)\n",
    "pi_emails_df_updated_monday['Contact Email'].fillna('-', inplace=True)\n",
    "pi_emails_df_updated_monday['pi_email_updated'] = [me if (len(e)==0 and len(me) > 1) else e for (e,me) in pi_emails_df_updated_monday[['pi_email', 'Contact Email']].values]\n",
    "print(pi_emails_df_updated_monday)\n",
    "pi_emails_df_updated_monday.to_csv(input_dir/\"email_updates.csv\", index=False)\n",
    "appl_ids_emails.to_csv(input_dir/\"email_counts.csv\", index=False)\n",
    "\n",
    "pi_emails_df_updated = pi_emails_df_updated_monday[['study_most_recent_appl', 'pi_email_updated']].rename(columns={'pi_email_updated':'pi_email'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Collect fields from report/awards tables that are required by Monday Board\n",
    "rename_dict = {'proj_num':'Project #', \n",
    "               'proj_title':'Title',\n",
    "                'rfa':'Research Focus',\n",
    "                'res_prg':'Research Program',\n",
    "                'ctc_pi_nm':'Contact PI',\n",
    "                'pi_email':'Contact Email',\n",
    "                'adm_ic':'Administering IC',\n",
    "                'prg_ofc':'NIH PO',\n",
    "                'org_nm': 'Institution(s)',\n",
    "                'pi':'PI(s)',\n",
    "                'org_cy':'City',\n",
    "                'org_st':'State',\n",
    "                'act_code':'Activity Code',\n",
    "                'awd_ty':'Award Type',\n",
    "                'fisc_yr':'Award Year',\n",
    "                'tot_fund':'Total Funded',\n",
    "                'proj_abs':'Summary',\n",
    "                'fund_mech': 'SBIR/STTR',\n",
    "                'dai_res':'DAI Import Status',\n",
    "                'proj_strt_date':'Project Start',\n",
    "                'proj_end_date':'Project End',\n",
    "                'proj_url':'Reporter Link',\n",
    "                'res_net':'Research Network',\n",
    "                'repo_22_1':'Repo Mapping',\n",
    "                'repo_22_2':'repo_22_2',\n",
    "                'repo_22_3':'repo_22_3',\n",
    "                'time_of_registration':'Platform Reg Time',\n",
    "                'overall_percent_complete':'CEDAR Form %',\n",
    "                'repository_name' : 'Repo per Platform',\n",
    "                'archived':'Archived',\n",
    "                'heal_funded':'HEAL-Related'\n",
    "                }\n",
    "\n",
    "def create_mysql_subset(in_df:pd.DataFrame, extra_fields = ['appl_id']):\n",
    "    subset = in_df[[k for k in rename_dict.keys() if k in in_df.columns] + extra_fields].copy(deep=True)\n",
    "    subset.rename(columns={k:v for k,v in rename_dict.items() if k in in_df.columns}, inplace=True)\n",
    "    return subset\n",
    "    \n",
    "mysql_fields_reporter = create_mysql_subset(awards_df)\n",
    "mysql_fields_awards = create_mysql_subset(reporter_df)\n",
    "myql_fields_repomapping = create_mysql_subset(repo_maping_df)\n",
    "mysql_fields_platform = create_mysql_subset(progress_tracker_df, extra_fields=['hdp_id'])\n",
    "mysql_fields_piemails = create_mysql_subset(pi_emails_df_updated, extra_fields=['study_most_recent_appl'])\n",
    "mysql_fields_resnet = create_mysql_subset(resnet_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n",
      "1200\n"
     ]
    }
   ],
   "source": [
    "print(len(lookup_fields))\n",
    "data_merge_1 = pd.merge(lookup_fields, mysql_fields_reporter, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_1))\n",
    "data_merge_2 = pd.merge(data_merge_1, mysql_fields_awards, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_2))\n",
    "data_merge_1 = pd.merge(data_merge_2, myql_fields_repomapping, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_1))\n",
    "data_merge_2 = pd.merge(data_merge_1, mysql_fields_platform, how='left', left_on='study_hdp_id', right_on='hdp_id')\n",
    "print(len(data_merge_2))\n",
    "data_merge_1 = pd.merge(data_merge_2, mysql_fields_resnet, how='left', left_on='study_most_recent_appl', right_on='appl_id').drop(columns='appl_id')\n",
    "print(len(data_merge_1))\n",
    "combined_data_ph1 = pd.merge(data_merge_1, mysql_fields_piemails, how='left', on='study_most_recent_appl')\n",
    "print(len(combined_data_ph1))\n",
    "print(len(combined_data_ph1.drop_duplicates()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of empty values for each of the fields gathered:\n",
      "Project # : 1\n",
      "Title : 1\n",
      "Research Focus : 14\n",
      "Research Program : 78\n",
      "Contact PI : 1\n",
      "Contact Email : 0\n",
      "Administering IC : 1\n",
      "NIH PO : 59\n",
      "Institution(s) : 1\n",
      "PI(s) : 1\n",
      "City : 6\n",
      "State : 8\n",
      "Activity Code : 1\n",
      "Award Type : 1\n",
      "Award Year : 1\n",
      "Total Funded : 1\n",
      "Summary : 9\n",
      "SBIR/STTR : 1\n",
      "DAI Import Status : 709\n",
      "Project Start : 1\n",
      "Project End : 1\n",
      "Reporter Link : 1\n",
      "Research Network : 775\n",
      "Repo Mapping : 733\n",
      "repo_22_2 : 1092\n",
      "repo_22_3 : 1192\n",
      "Platform Reg Time : 844\n",
      "CEDAR Form % : 38\n",
      "Repo per Platform : 1036\n",
      "Archived : 38\n",
      "HEAL-Related : 22\n"
     ]
    }
   ],
   "source": [
    "## Find out which columns have NA values, and investigate for incompletemess?\n",
    "print(\"Number of empty values for each of the fields gathered:\")\n",
    "for k in rename_dict.values():\n",
    "    print(f\"{k} : {get_na_count(combined_data_ph1, k)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/1795575434.py:18: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  progress_tracker_data['project_title'].replace('0', '', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/1795575434.py:21: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  progress_tracker_data['PI(s)'].fillna('', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# This cell is meant to fill in holes in the mysql data from the progress tracker a.k.a platform MDS data.\n",
    "\n",
    "rename_dict = {'project_num':'Project #', \n",
    "               'project_title':'Title',\n",
    "                'investigators_name':'PI(s)',\n",
    "                'award_type':'Award Type',\n",
    "                'year_awarded':'Award Year',\n",
    "                'award_amount':'Total Funded',\n",
    "                'study_name':'Summary',\n",
    "                'project_end_date':'Project End',\n",
    "                'nih_reporter_link':'Reporter Link',\n",
    "                'time_of_registration':'Platform Reg Time',\n",
    "                'overall_percent_complete':'CEDAR Form %',\n",
    "                'repository_name' : 'Repo per Platform',\n",
    "                'archived':'Archived',\n",
    "                }\n",
    "progress_tracker_data = progress_tracker_df.copy(deep=True)\n",
    "progress_tracker_data['project_title'].replace('0', '', inplace=True)\n",
    "progress_tracker_data = create_mysql_subset(progress_tracker_data, extra_fields=['hdp_id'])\n",
    "\n",
    "progress_tracker_data['PI(s)'].fillna('', inplace=True)\n",
    "progress_tracker_data['PI(s)'] = [ k.translate(str.maketrans(',', ';', \"[]\\'\")) for k in  progress_tracker_data['PI(s)']]\n",
    "\n",
    "progress_tracker_data['key'] = progress_tracker_data['hdp_id']\n",
    "progress_tracker_data['study_hdp_id'] = progress_tracker_data['hdp_id']\n",
    "progress_tracker_data['Research Network'] = [ 'CTN' if k.startswith('CTN') else '' for k in progress_tracker_data['Project #']]\n",
    "\n",
    "fill_in_data = pd.merge(combined_data_ph1, progress_tracker_data, how='left', on='study_hdp_id')\n",
    "fill_in_data.to_csv(input_dir/\"tmp.csv\", index=False)\n",
    "\n",
    "\n",
    "columns_to_compare = list(rename_dict.values())\n",
    "columns_to_compare.extend(['key', 'Research Network'])\n",
    "\n",
    "for k in columns_to_compare:\n",
    "    k_x = k+'_x'\n",
    "    k_y = k+'_y'\n",
    "    fill_in_data[k] = [v_y if pd.isna(v_x) else v_x for (v_x, v_y) in fill_in_data[[k_x, k_y]].values]\n",
    "    fill_in_data.drop(columns=[k_x, k_y], inplace=True)\n",
    "\n",
    "columns = fill_in_data.columns.sort_values()\n",
    "fill_in_data = fill_in_data[columns]\n",
    "fill_in_data.to_csv(input_dir/\"tmp.csv\", index=False)\n",
    "combined_data_ph1 = fill_in_data.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/3673277832.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ctn_data['project_title'].replace('0', '', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/3673277832.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  ctn_data['project_title'].replace('0', '', inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_29842/3673277832.py:22: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  ctn_fields_platform['PI(s)'].fillna('', inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Activity Code</th>\n",
       "      <th>Administering IC</th>\n",
       "      <th>Archived</th>\n",
       "      <th>Award Type</th>\n",
       "      <th>Award Year</th>\n",
       "      <th>CEDAR Form %</th>\n",
       "      <th>City</th>\n",
       "      <th>Contact Email</th>\n",
       "      <th>Contact PI</th>\n",
       "      <th>DAI Import Status</th>\n",
       "      <th>...</th>\n",
       "      <th>Total Funded</th>\n",
       "      <th>hdp_id_x</th>\n",
       "      <th>hdp_id_y</th>\n",
       "      <th>key</th>\n",
       "      <th>repo_22_2</th>\n",
       "      <th>repo_22_3</th>\n",
       "      <th>study_hdp_id</th>\n",
       "      <th>study_hdp_id_appl</th>\n",
       "      <th>study_most_recent_appl</th>\n",
       "      <th>hdp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>U01</td>\n",
       "      <td>NIAAA</td>\n",
       "      <td>live</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>PORTLAND</td>\n",
       "      <td></td>\n",
       "      <td>NAGEL, BONNIE J</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>93429.0</td>\n",
       "      <td>HDP00632</td>\n",
       "      <td>HDP00632</td>\n",
       "      <td>HDP00632</td>\n",
       "      <td>Vivli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP00632</td>\n",
       "      <td>9860408</td>\n",
       "      <td>9860408</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R34</td>\n",
       "      <td>NIAAA</td>\n",
       "      <td>live</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SANTA MONICA</td>\n",
       "      <td>kwatkins@rand.org</td>\n",
       "      <td>WATKINS, KATHERINE E</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>99988.0</td>\n",
       "      <td>HDP00696</td>\n",
       "      <td>HDP00696</td>\n",
       "      <td>HDP00696</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP00696</td>\n",
       "      <td>9755001</td>\n",
       "      <td>9755001</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R01</td>\n",
       "      <td>NIAAA</td>\n",
       "      <td>live</td>\n",
       "      <td>3</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>SANTA MONICA</td>\n",
       "      <td>damico@rand.org</td>\n",
       "      <td>D'AMICO, ELIZABETH J.</td>\n",
       "      <td>NO</td>\n",
       "      <td>...</td>\n",
       "      <td>182670.0</td>\n",
       "      <td>HDP00509</td>\n",
       "      <td>HDP00509</td>\n",
       "      <td>HDP00509</td>\n",
       "      <td>Vivli</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP00509</td>\n",
       "      <td>9850412</td>\n",
       "      <td>9850412</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UH3</td>\n",
       "      <td>NIA</td>\n",
       "      <td>live</td>\n",
       "      <td>5</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>80.8</td>\n",
       "      <td>OAKLAND</td>\n",
       "      <td>LYNN.DEBAR@KP.ORG</td>\n",
       "      <td>DEBAR, LYNN L.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>2200655.0</td>\n",
       "      <td>HDP00242</td>\n",
       "      <td>HDP00242</td>\n",
       "      <td>HDP00242</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP00242</td>\n",
       "      <td>9869480</td>\n",
       "      <td>10478911</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UH3</td>\n",
       "      <td>NIA</td>\n",
       "      <td>live</td>\n",
       "      <td>5</td>\n",
       "      <td>2022.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>ROCHESTER</td>\n",
       "      <td>cheville.andrea@mayo.edu</td>\n",
       "      <td>CHEVILLE, ANDREA LYNNE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1506116.0</td>\n",
       "      <td>HDP00391</td>\n",
       "      <td>HDP00391</td>\n",
       "      <td>HDP00391</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP00391</td>\n",
       "      <td>9876435</td>\n",
       "      <td>10468778</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01320</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01321</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1317</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1318</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>live</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01324</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>HDP01324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1240 rows Ã— 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Activity Code Administering IC Archived Award Type  Award Year  \\\n",
       "0              U01            NIAAA     live          3      2019.0   \n",
       "1              R34            NIAAA     live          3      2019.0   \n",
       "2              R01            NIAAA     live          3      2019.0   \n",
       "3              UH3              NIA     live          5      2022.0   \n",
       "4              UH3              NIA     live          5      2022.0   \n",
       "...            ...              ...      ...        ...         ...   \n",
       "1314           NaN              NaN     live          0         NaN   \n",
       "1315           NaN              NaN     live          0         NaN   \n",
       "1316           NaN              NaN     live          0         NaN   \n",
       "1317           NaN              NaN     live          0         NaN   \n",
       "1318           NaN              NaN     live          0         NaN   \n",
       "\n",
       "      CEDAR Form %          City             Contact Email  \\\n",
       "0              0.0      PORTLAND                             \n",
       "1              0.0  SANTA MONICA         kwatkins@rand.org   \n",
       "2              0.0  SANTA MONICA           damico@rand.org   \n",
       "3             80.8       OAKLAND         LYNN.DEBAR@KP.ORG   \n",
       "4             25.0     ROCHESTER  cheville.andrea@mayo.edu   \n",
       "...            ...           ...                       ...   \n",
       "1314           0.0           NaN                       NaN   \n",
       "1315          76.9           NaN                       NaN   \n",
       "1316           0.0           NaN                       NaN   \n",
       "1317           0.0           NaN                       NaN   \n",
       "1318           0.0           NaN                       NaN   \n",
       "\n",
       "                  Contact PI DAI Import Status  ... Total Funded  hdp_id_x  \\\n",
       "0            NAGEL, BONNIE J                NO  ...      93429.0  HDP00632   \n",
       "1       WATKINS, KATHERINE E                NO  ...      99988.0  HDP00696   \n",
       "2      D'AMICO, ELIZABETH J.                NO  ...     182670.0  HDP00509   \n",
       "3             DEBAR, LYNN L.               NaN  ...    2200655.0  HDP00242   \n",
       "4     CHEVILLE, ANDREA LYNNE               NaN  ...    1506116.0  HDP00391   \n",
       "...                      ...               ...  ...          ...       ...   \n",
       "1314                     NaN               NaN  ...          0.0       NaN   \n",
       "1315                     NaN               NaN  ...          0.0       NaN   \n",
       "1316                     NaN               NaN  ...          0.0       NaN   \n",
       "1317                     NaN               NaN  ...          0.0       NaN   \n",
       "1318                     NaN               NaN  ...          0.0       NaN   \n",
       "\n",
       "      hdp_id_y       key repo_22_2 repo_22_3 study_hdp_id study_hdp_id_appl  \\\n",
       "0     HDP00632  HDP00632     Vivli       NaN     HDP00632           9860408   \n",
       "1     HDP00696  HDP00696       NaN       NaN     HDP00696           9755001   \n",
       "2     HDP00509  HDP00509     Vivli       NaN     HDP00509           9850412   \n",
       "3     HDP00242  HDP00242       NaN       NaN     HDP00242           9869480   \n",
       "4     HDP00391  HDP00391       NaN       NaN     HDP00391           9876435   \n",
       "...        ...       ...       ...       ...          ...               ...   \n",
       "1314       NaN  HDP01320       NaN       NaN     HDP01320               NaN   \n",
       "1315       NaN  HDP01321       NaN       NaN     HDP01321               NaN   \n",
       "1316       NaN  HDP01322       NaN       NaN     HDP01322               NaN   \n",
       "1317       NaN  HDP01323       NaN       NaN     HDP01323               NaN   \n",
       "1318       NaN  HDP01324       NaN       NaN     HDP01324               NaN   \n",
       "\n",
       "     study_most_recent_appl    hdp_id  \n",
       "0                   9860408       NaN  \n",
       "1                   9755001       NaN  \n",
       "2                   9850412       NaN  \n",
       "3                  10478911       NaN  \n",
       "4                  10468778       NaN  \n",
       "...                     ...       ...  \n",
       "1314                    NaN  HDP01320  \n",
       "1315                    NaN  HDP01321  \n",
       "1316                    NaN  HDP01322  \n",
       "1317                    NaN  HDP01323  \n",
       "1318                    NaN  HDP01324  \n",
       "\n",
       "[1240 rows x 38 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Add CTN  data \n",
    "ctn_data = progress_tracker_df[[k.startswith('CTN') for k in progress_tracker_df['project_num']]]\n",
    "ctn_data['project_title'].replace('0', '', inplace=True)\n",
    "\n",
    "print(len(ctn_data))\n",
    "rename_dict = {'project_num':'Project #', \n",
    "               'project_title':'Title',\n",
    "                'investigators_name':'PI(s)',\n",
    "                'award_type':'Award Type',\n",
    "                'year_awarded':'Award Year',\n",
    "                'award_amount':'Total Funded',\n",
    "                'study_name':'Summary',\n",
    "                'proj_end_date':'Project End',\n",
    "                'nih_reporter_link':'Reporter Link',\n",
    "                'time_of_registration':'Platform Reg Time',\n",
    "                'overall_percent_complete':'CEDAR Form %',\n",
    "                'repository_name' : 'Repo per Platform',\n",
    "                'archived':'Archived',\n",
    "                }\n",
    "ctn_fields_platform = create_mysql_subset(ctn_data, extra_fields=['hdp_id'])\n",
    "## Edit pi name\n",
    "ctn_fields_platform['PI(s)'].fillna('', inplace=True)\n",
    "ctn_fields_platform['PI(s)'] = [ k.translate(str.maketrans(',', ';', \"[]\\'\")) for k in  ctn_fields_platform['PI(s)']]\n",
    "\n",
    "ctn_fields_platform['key'] = ctn_fields_platform['hdp_id']\n",
    "ctn_fields_platform['study_hdp_id'] = ctn_fields_platform['hdp_id']\n",
    "ctn_fields_platform['Research Network'] = ['CTN']*len(ctn_fields_platform)\n",
    "\n",
    "## Combine the data to the other data set\n",
    "all_data = pd.concat([combined_data_ph1, ctn_fields_platform])\n",
    "all_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Research Network\n",
       "CTN                    188\n",
       "HBCD                   132\n",
       "JCOIN                   79\n",
       "BACPAC                  66\n",
       "PAIN ERN                39\n",
       "EPPIC-NET               36\n",
       "ACT NOW                 32\n",
       "HPC                     28\n",
       "PRISM                   27\n",
       "HEALING COMMUNITIES     23\n",
       "DATA 2 ACTION           18\n",
       "IMPOWR                  16\n",
       "HOPE                    14\n",
       "HARM REDUCTION          11\n",
       "MFMU                     5\n",
       "A2CPS                    5\n",
       "PRECISION                5\n",
       "RE-JOIN                  5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mysql_fields_resnet['Research Network'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = all_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "study_type\n",
      "HDP           1162\n",
      "CTN             40\n",
      "APPLIDONLY      38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "## Create a column named \"Location\"dd\n",
    "from datetime import datetime\n",
    "combined_data['study_type'] = [ 'CTN' if m.startswith('CTN') else ('APPLIDONLY' if pd.isna(k) else 'HDP') for (m,k) in combined_data[['Project #', 'study_hdp_id_appl']].values]\n",
    "\n",
    "combined_data['City'] = combined_data[['City']].fillna('-')\n",
    "combined_data['State'] = combined_data[['State']].fillna('-')\n",
    "combined_data['Location'] = [c+\",\"+s for (c,s) in combined_data[['City', \"State\"]].values]\n",
    "\n",
    "combined_data['Project Start'] = pd.to_datetime(combined_data['Project Start'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "combined_data['Project End'] = pd.to_datetime(combined_data['Project End'], format='%Y-%m-%d', errors='coerce').dt.date\n",
    "combined_data['Platform Reg Time'] = pd.to_datetime(combined_data['Platform Reg Time'], utc=True).dt.date\n",
    "\n",
    "combined_data['Archived'] = [a if a=='archived' else 'n' for a in combined_data['Archived']]\n",
    "\n",
    "combined_data['HEAL-Related'] = ['Y' if ((p != 'CTN' ) and (pd.isna(a))) else 'N' for (p,a) in combined_data[['study_type', 'HEAL-Related']].values]\n",
    "combined_data['SBIR/STTR'] = ['Y' if 'SBIR/STTR'==t else 'N' for t in combined_data['SBIR/STTR']]\n",
    "\n",
    "print(combined_data.study_type.value_counts())\n",
    "\n",
    "## Rename a few of the other columns:\n",
    "combined_data.rename(columns={'study_most_recent_appl':'Most Recent Appl_ID', 'study_hdp_id_appl':'HDP appl_ID'}, inplace=True)\n",
    "combined_data.drop(columns=['study_hdp_id', 'hdp_id', 'hdp_id_x', 'hdp_id_y'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36\n",
      "23\n",
      "10\n",
      "['Activity Code', 'Administering IC', 'Award Type', 'Contact Email', 'Contact PI', 'DAI Import Status', 'Institution(s)', 'NIH PO', 'PI(s)', 'Project #', 'Repo Mapping', 'Repo per Platform', 'Reporter Link', 'Research Focus', 'Research Network', 'Research Program', 'Summary', 'Title', 'key', 'repo_22_2', 'repo_22_3', 'HDP appl_ID', 'Most Recent Appl_ID']\n"
     ]
    }
   ],
   "source": [
    "handled_columns = ['study_type', 'City', 'State', 'Location', 'Project Start', 'Project End', 'Platform Reg Time', 'Archived', 'HEAL-Related', 'SBIR/STTR']\n",
    "rest_obj_columns = [k for k in combined_data.columns if k not in handled_columns and combined_data[k].dtype in ['object', 'str']]\n",
    "\n",
    "#combined_data[rest_obj_columns].fillna('-')\n",
    "print(len(combined_data.columns))\n",
    "print(len(rest_obj_columns))\n",
    "print(len(handled_columns))\n",
    "print(rest_obj_columns)\n",
    "\n",
    "for k in rest_obj_columns:\n",
    "    combined_data[k] = ['-' if (t is np.NaN) or (t=='') else t for t in combined_data[k]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Find what's in Monday.com board, but not in mysql extract\n",
    "# Mark these entries for deletion, and these would have to be deleted manually on Monday.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_data_subset = combined_data[ combined_data['Most Recent Appl_ID'].isin(monday_board['Most Recent Appl_ID']) | combined_data['key'].isin(monday_board['Name'])].drop_duplicates()\n",
    "# combined_data_subset = combined_data_subset[ ~pd.isna(combined_data_subset['Most Recent Appl_ID']) ]\n",
    "# print(len(combined_data_subset))\n",
    "# combined_data_subset.to_excel(input_dir/\"MondayBoard_Update_Step2.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making sure uniqueness of key values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1240.0\n",
       "mean        1.0\n",
       "std         0.0\n",
       "min         1.0\n",
       "25%         1.0\n",
       "50%         1.0\n",
       "75%         1.0\n",
       "max         1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.index.name = 'index'\n",
    "combined_data.to_excel(input_dir/\"MondayBoard_Update.xlsx\")\n",
    "\n",
    "print(\"Making sure uniqueness of key values\")\n",
    "key_counts = combined_data.groupby('key').size()\n",
    "key_counts.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************\n",
    "*******************\n",
    "DEBUG CODE BELOW\n",
    "*******************\n",
    "*******************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Most Recent Appl_ID</th>\n",
       "      <th>HDP appl_ID</th>\n",
       "      <th>key</th>\n",
       "      <th>Research Focus</th>\n",
       "      <th>Research Program</th>\n",
       "      <th>DAI Import Status</th>\n",
       "      <th>HEAL-Related</th>\n",
       "      <th>Project #</th>\n",
       "      <th>Title</th>\n",
       "      <th>Contact PI</th>\n",
       "      <th>...</th>\n",
       "      <th>repo_22_2</th>\n",
       "      <th>repo_22_3</th>\n",
       "      <th>Platform Reg Time</th>\n",
       "      <th>CEDAR Form %</th>\n",
       "      <th>Repo per Platform</th>\n",
       "      <th>Archived</th>\n",
       "      <th>Network</th>\n",
       "      <th>Contact Email</th>\n",
       "      <th>Location</th>\n",
       "      <th>study_type</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>10593312</td>\n",
       "      <td>10601172</td>\n",
       "      <td>HDP00889</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Y</td>\n",
       "      <td>3R24DA055306-02S1</td>\n",
       "      <td>Wake Forest IMPOWR Dissemination Education and...</td>\n",
       "      <td>ADAMS, MEREDITH C. B.</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-07-26</td>\n",
       "      <td>5.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>meradams@wakehealth.edu</td>\n",
       "      <td>WINSTON-SALEM,NC</td>\n",
       "      <td>HDP</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Most Recent Appl_ID HDP appl_ID       key Research Focus  \\\n",
       "index                                                            \n",
       "660              10593312    10601172  HDP00889            NaN   \n",
       "\n",
       "      Research Program DAI Import Status HEAL-Related          Project #  \\\n",
       "index                                                                      \n",
       "660                NaN               NaN            Y  3R24DA055306-02S1   \n",
       "\n",
       "                                                   Title  \\\n",
       "index                                                      \n",
       "660    Wake Forest IMPOWR Dissemination Education and...   \n",
       "\n",
       "                  Contact PI  ... repo_22_2 repo_22_3 Platform Reg Time  \\\n",
       "index                         ...                                         \n",
       "660    ADAMS, MEREDITH C. B.  ...       NaN       NaN        2022-07-26   \n",
       "\n",
       "      CEDAR Form % Repo per Platform Archived Network  \\\n",
       "index                                                   \n",
       "660            5.8               NaN              NaN   \n",
       "\n",
       "                 Contact Email          Location  study_type  \n",
       "index                                                         \n",
       "660    meradams@wakehealth.edu  WINSTON-SALEM,NC         HDP  \n",
       "\n",
       "[1 rows x 36 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data[combined_data['key']=='HDP00889'].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_cols = ['Most Recent Appl_ID', 'HDP appl_ID', 'Contact Email', 'Network']\n",
    "\n",
    "comparison_df = pd.merge(monday_board[['Name'] +comparison_cols ], combined_data[['key'] + comparison_cols], left_on = 'Name', right_on='key').drop_duplicates()\n",
    "comparison_df.to_csv(input_dir/\"comparison.csv\", index=False)\n",
    "comparison_df.to_excel(input_dir/\"comparison.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>study_most_recent_appl</th>\n",
       "      <th>pi_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>9901704</td>\n",
       "      <td>jhambm@upmc.edu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    study_most_recent_appl         pi_email\n",
       "881                9901704  jhambm@upmc.edu"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_emails_df_updated[ pi_emails_df_updated.study_most_recent_appl=='9901704']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appl_id</th>\n",
       "      <th>res_net</th>\n",
       "      <th>res_net_override_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1486</th>\n",
       "      <td>9908734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      appl_id res_net  res_net_override_flag\n",
       "1486  9908734     NaN                      0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet_df[resnet_df.appl_id=='9908734']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
