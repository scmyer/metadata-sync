{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = Path(\"/Users/hinashah/Documents/HEAL/MondayBoard/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_appl_ids(df:pd.DataFrame):\n",
    "    if 'appl_id' in df.columns:\n",
    "        return df[ ~pd.isna(df['appl_id'])]['appl_id'].drop_duplicates()\n",
    "    return None\n",
    "    \n",
    "def get_unique_hdp_ids(df:pd.DataFrame):\n",
    "    if 'hdp_id' in df.columns:\n",
    "        return df[ ~pd.isna(df['hdp_id'])]['hdp_id'].drop_duplicates()\n",
    "    return None\n",
    "\n",
    "def convert_appl_ids_tostr(df:pd.DataFrame, appl_id_col:str='appl_id'):\n",
    "    if appl_id_col not in df.columns:\n",
    "        print(\"No appl_id columns available\")\n",
    "        return\n",
    "\n",
    "    if df[appl_id_col].dtypes == 'int64':\n",
    "        df[appl_id_col].fillna(-1, inplace=True)\n",
    "        df[appl_id_col] = df[appl_id_col].astype('str')\n",
    "    elif df[appl_id_col].dtypes == 'float64':\n",
    "        df[appl_id_col].fillna(-1, inplace=True)\n",
    "        df[appl_id_col] = df[appl_id_col].astype('int64').astype('str')\n",
    "    elif df[appl_id_col].dtypes == 'object':\n",
    "        print(\"Nothing to do here\")\n",
    "    else:\n",
    "        print(f\"Dtype is: {df[appl_id_col].dtypes}, cannot be converted yet\")\n",
    "        return\n",
    "    df[appl_id_col].replace(\"-1\", np.NaN, inplace=True)\n",
    "\n",
    "def get_missing_applids(expected: set, df:pd.DataFrame):\n",
    "    appl_id_col = 'appl_id'\n",
    "    return [k for k in expected if k not in df[appl_id_col].values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Awards table has: 1588 entries, with 1588 appl_ids\n",
      "Reporter table has: 1590 entriesawards_df, with 1590 appl_ids\n",
      "Platform generated table has: 1279 entries, with 1270 appl_ids\n",
      "Platform table has 1279 unique HDP IDs\n"
     ]
    }
   ],
   "source": [
    "#MATCH!\n",
    "awards_df = pd.read_csv(input_dir/\"awards.csv\", low_memory=False)\n",
    "awards_df = awards_df.dropna(how='all')\n",
    "print(f\"Awards table has: {len(awards_df)} entries, with {len(get_unique_appl_ids(awards_df))} appl_ids\")\n",
    "reporter_df = pd.read_csv(input_dir/\"reporter.csv\", low_memory=False)\n",
    "reporter_df = reporter_df.dropna(how='all')\n",
    "print(f\"Reporter table has: {len(reporter_df)} entriesawards_df, with {len(get_unique_appl_ids(reporter_df))} appl_ids\")\n",
    "progress_tracker_df = pd.read_csv(input_dir/\"progress_tracker.csv\", low_memory=False)\n",
    "print(f\"Platform generated table has: {len(progress_tracker_df)} entries, with {len(get_unique_appl_ids(progress_tracker_df))} appl_ids\")\n",
    "print(f\"Platform table has {len(get_unique_hdp_ids(progress_tracker_df))} unique HDP IDs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:20: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].fillna(-1, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].replace(\"-1\", np.NaN, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].fillna(-1, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].replace(\"-1\", np.NaN, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].fillna(-1, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].replace(\"-1\", np.NaN, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "convert_appl_ids_tostr(awards_df)\n",
    "convert_appl_ids_tostr(reporter_df)\n",
    "convert_appl_ids_tostr(progress_tracker_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1279\n",
      "[]\n",
      "Project numbers with a lowercase letter that might have been added by platform: \n",
      "[]\n",
      "List of appl_ids for which multiple HDPID s are assigned::\n",
      "appl_id\n",
      "10267804    3\n",
      "10378422    2\n",
      "10378910    2\n",
      "10378923    2\n",
      "10391075    3\n",
      "10590474    3\n",
      "dtype: int64\n",
      "       appl_id    hdp_id\n",
      "1047  10267804  HDP01050\n",
      "216   10267804  HDP00218\n",
      "1048  10267804  HDP01051\n",
      "38    10378422  HDP00039\n",
      "1042  10378422  HDP01045\n",
      "1043  10378910  HDP01046\n",
      "278   10378910  HDP00280\n",
      "1044  10378923  HDP01047\n",
      "288   10378923  HDP00290\n",
      "1046  10391075  HDP01049\n",
      "1045  10391075  HDP01048\n",
      "105   10391075  HDP00106\n",
      "1009  10590474  HDP01012\n",
      "1276  10590474  HDP01282\n",
      "1277  10590474  HDP01283\n"
     ]
    }
   ],
   "source": [
    "## Match\n",
    "print(len(progress_tracker_df))\n",
    "progress_tracker_df = progress_tracker_df.sort_values(\"appl_id\")\n",
    "appl_ids_wrong = [k for k in progress_tracker_df.appl_id if (k==\"0\") | ('-' in k) ]\n",
    "print(appl_ids_wrong)\n",
    "## Remove any rows with appl_id=\"0\"\n",
    "progress_tracker_df = progress_tracker_df[ ~progress_tracker_df.appl_id.isin([\"0\"]) ]\n",
    "## Matched with Sabrina the project numbers that will not make into the dataset because of funky project numbers\n",
    "## HDP00885\n",
    "## HDP00886\n",
    "## HDP00882\n",
    "## HDP00881\n",
    "## HDP00883\n",
    "## HDP00884\n",
    "progress_tracker_df['num_dashes'] = [len( [a for a in k if a=='-'] ) for k in progress_tracker_df.project_num]\n",
    "# Remove anything after '_' (this also removes lower case letters, but a check should be made below)\n",
    "progress_tracker_df['project_num'] = [k.split('_')[0] for k in progress_tracker_df['project_num']]\n",
    "# Reset the project number to blank for anything that has more than one dashes\n",
    "progress_tracker_df['project_num'] = [\"\" if n > 1 else k for (k,n) in progress_tracker_df[['project_num', 'num_dashes']].values]\n",
    "# progress_tracker_df['project_num'] = [k.replace() for k in progress_tracker_df['project_num']]\n",
    "print(\"Project numbers with a lowercase letter that might have been added by platform: \")\n",
    "print([k for k in progress_tracker_df.project_num if re.search(r'[a-z]', k) is not None])\n",
    "\n",
    "## Create project number components\n",
    "progress_tracker_df['mds_proj_num_spl_ty_code'] = [k[0] if len(k) > 0 else k for k in progress_tracker_df['project_num']]\n",
    "progress_tracker_df['mds_pproj_num_spl_act_code'] = [k[1:4] if len(k) > 0 else k for k in progress_tracker_df['project_num']]\n",
    "progress_tracker_df['mds_proj_ser_num'] = [k[4:12] if len(k) > 0 else k for k in progress_tracker_df['project_num']]\n",
    "progress_tracker_df['mds_proj_nm_spl_supp_yr'] = [k.split('-')[1] if len(k) > 0 else k for k in progress_tracker_df['project_num']]\n",
    "progress_tracker_df['mds_proj_num_spl_sfx_code'] = [k[2:] if len(k) > 0 else k for k in progress_tracker_df['mds_proj_nm_spl_supp_yr']]\n",
    "\n",
    "progress_tracker_df[ ['project_num'] + [k for k in progress_tracker_df.columns if k.startswith('mds')]]\n",
    "progress_tracker_df.rename(columns={'project_num':'mds_project_num'}, inplace=True)\n",
    "# Cound hdp_ids for appl_ids\n",
    "appl_hdp = progress_tracker_df[['appl_id', 'hdp_id']].drop_duplicates()\n",
    "t = appl_hdp.groupby('appl_id').size()\n",
    "\n",
    "print(\"List of appl_ids for which multiple HDPID s are assigned::\")\n",
    "print(t[t!=1])\n",
    "print(appl_hdp[ appl_hdp.appl_id.isin(t[t!=1].keys())])\n",
    "progress_tracker_df['num_hdp_by_appl'] = [t[k] for k in progress_tracker_df['appl_id']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>proj_abs</th>\n",
       "      <th>act_code</th>\n",
       "      <th>ic_code</th>\n",
       "      <th>adm_ic</th>\n",
       "      <th>adm_ic_code</th>\n",
       "      <th>adm_ic_nm</th>\n",
       "      <th>fund_ic</th>\n",
       "      <th>ic_fund_code</th>\n",
       "      <th>ic_fund_yr</th>\n",
       "      <th>fund_ic_nm</th>\n",
       "      <th>...</th>\n",
       "      <th>trms</th>\n",
       "      <th>rfa</th>\n",
       "      <th>res_prg</th>\n",
       "      <th>spcf_aims</th>\n",
       "      <th>dai_res</th>\n",
       "      <th>res_net</th>\n",
       "      <th>goal</th>\n",
       "      <th>data_src</th>\n",
       "      <th>heal_funded</th>\n",
       "      <th>data_mgmt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>From 2009-2013 the utilization of the Schedule...</td>\n",
       "      <td>R44</td>\n",
       "      <td>NIH</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>DA</td>\n",
       "      <td>National Institute on Drug Abuse</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>DA</td>\n",
       "      <td>2020</td>\n",
       "      <td>National Institute on Drug Abuse</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;Oral Administration&gt;&lt;Oral Drug Administration...</td>\n",
       "      <td>Cross-Cutting Research</td>\n",
       "      <td>Small Business Programs</td>\n",
       "      <td>The most commonly prescribed opioids in the fi...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cross-Cutting Research</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBIR/STTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>From 2009-2013 the utilization of the Schedule...</td>\n",
       "      <td>R44</td>\n",
       "      <td>NIH</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>DA</td>\n",
       "      <td>National Institute on Drug Abuse</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>DA</td>\n",
       "      <td>2021</td>\n",
       "      <td>National Institute on Drug Abuse</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;Oral Administration&gt;&lt;Oral Drug Administration...</td>\n",
       "      <td>Cross-Cutting Research</td>\n",
       "      <td>Small Business Programs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cross-Cutting Research</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBIR/STTR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1001</th>\n",
       "      <td>From 2009-2013 the utilization of the Schedule...</td>\n",
       "      <td>R44</td>\n",
       "      <td>NIH</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>DA</td>\n",
       "      <td>National Institute on Drug Abuse</td>\n",
       "      <td>NIDA</td>\n",
       "      <td>DA</td>\n",
       "      <td>2019</td>\n",
       "      <td>National Institute on Drug Abuse</td>\n",
       "      <td>...</td>\n",
       "      <td>&lt;Oral Administration&gt;&lt;intraoral drug delivery&gt;...</td>\n",
       "      <td>Cross-Cutting Research</td>\n",
       "      <td>Small Business Programs</td>\n",
       "      <td>The most commonly prescribed opioids in the fi...</td>\n",
       "      <td>NO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cross-Cutting Research</td>\n",
       "      <td>2</td>\n",
       "      <td>Y</td>\n",
       "      <td>SBIR/STTR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               proj_abs act_code ic_code  \\\n",
       "63    From 2009-2013 the utilization of the Schedule...      R44     NIH   \n",
       "350   From 2009-2013 the utilization of the Schedule...      R44     NIH   \n",
       "1001  From 2009-2013 the utilization of the Schedule...      R44     NIH   \n",
       "\n",
       "     adm_ic adm_ic_code                         adm_ic_nm fund_ic  \\\n",
       "63     NIDA          DA  National Institute on Drug Abuse    NIDA   \n",
       "350    NIDA          DA  National Institute on Drug Abuse    NIDA   \n",
       "1001   NIDA          DA  National Institute on Drug Abuse    NIDA   \n",
       "\n",
       "     ic_fund_code ic_fund_yr                        fund_ic_nm  ...  \\\n",
       "63             DA       2020  National Institute on Drug Abuse  ...   \n",
       "350            DA       2021  National Institute on Drug Abuse  ...   \n",
       "1001           DA       2019  National Institute on Drug Abuse  ...   \n",
       "\n",
       "                                                   trms  \\\n",
       "63    <Oral Administration><Oral Drug Administration...   \n",
       "350   <Oral Administration><Oral Drug Administration...   \n",
       "1001  <Oral Administration><intraoral drug delivery>...   \n",
       "\n",
       "                         rfa                  res_prg  \\\n",
       "63    Cross-Cutting Research  Small Business Programs   \n",
       "350   Cross-Cutting Research  Small Business Programs   \n",
       "1001  Cross-Cutting Research  Small Business Programs   \n",
       "\n",
       "                                              spcf_aims dai_res res_net  \\\n",
       "63    The most commonly prescribed opioids in the fi...      NO     NaN   \n",
       "350                                                 NaN     NaN     NaN   \n",
       "1001  The most commonly prescribed opioids in the fi...      NO     NaN   \n",
       "\n",
       "                        goal data_src  heal_funded  data_mgmt  \n",
       "63    Cross-Cutting Research        2            Y  SBIR/STTR  \n",
       "350   Cross-Cutting Research        2            Y  SBIR/STTR  \n",
       "1001  Cross-Cutting Research        2            Y  SBIR/STTR  \n",
       "\n",
       "[3 rows x 90 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data_1[combined_data_1.appl_id.isin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of reporter: 1590\n",
      "# of records after merging reporter and awards: 1591\n",
      "# of records after merging with platform: 1624\n",
      "Number of appl_ids in progress tracker that were not matched to reporter/awards:       24\n"
     ]
    }
   ],
   "source": [
    "### MATCH!\n",
    "# 1:m in Stata is the same as outer join in pandas??\n",
    "print(f\"Length of reporter: {len(reporter_df)}\")\n",
    "combined_data_1 = pd.merge(reporter_df, awards_df, how='outer', left_on='appl_id', right_on='appl_id').drop_duplicates()\n",
    "print(f\"# of records after merging reporter and awards: {len(combined_data_1)}\")\n",
    "combined_data = pd.merge(combined_data_1, progress_tracker_df, how='outer', left_on='appl_id', right_on='appl_id')\n",
    "print(f\"# of records after merging with platform: {len(combined_data)}\")\n",
    "\n",
    "print(f\"Number of appl_ids in progress tracker that were not matched to reporter/awards: \\\n",
    "      {len(progress_tracker_df[~progress_tracker_df.appl_id.isin(combined_data_1.appl_id)])}\")\n",
    "progress_tracker_df[~progress_tracker_df.appl_id.isin(combined_data_1.appl_id)].to_csv(input_dir/\"platform_applids_missing_inreporterawards.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This block is debugging\n",
    "s = combined_data[pd.isna(combined_data.proj_num_spl_sfx_code)][['proj_num', 'proj_num_spl_sfx_code', 'proj_ser_num', 'mds_proj_num_spl_sfx_code', 'mds_proj_ser_num', 'mds_project_num']]\n",
    "s.dropna(how='all', inplace=True)\n",
    "s.to_csv(input_dir/\"combined_data_qc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31\n",
      "Number of entries in merged dataset: 1624\n",
      "Number of entries with empty proj_ser_num which will be dropped: 7\n",
      "    proj_ser_num mds_proj_ser_num    hdp_id\n",
      "321          NaN                   HDP00885\n",
      "322          NaN                   HDP00886\n",
      "506          NaN                   HDP00882\n",
      "511          NaN                   HDP00881\n",
      "598          NaN                   HDP00883\n",
      "603          NaN                   HDP00884\n",
      "261          NaN              NaN       NaN\n",
      "*** Number of entries in merged dataset AFTER removing empty proj_ser_num: 1617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3260850226.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['proj_ser_num'].replace('', np.NaN, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## MATCH\n",
    "print(len(combined_data[pd.isna(combined_data.proj_ser_num)]))\n",
    "#print(combined_data[pd.isna(combined_data.proj_ser_num)][['proj_num', 'proj_num_spl_sfx_code', 'proj_ser_num', 'mds_proj_num_spl_sfx_code', 'mds_proj_ser_num', 'mds_project_num', 'hdp_id']])\n",
    "\n",
    "## Question: The following corresponds to line 157 from HEAL_MYSQL_01_ImportMerge.do., but it seems to be unnecessary. \n",
    "## Is my understanding correct that this is replacing the awards/reporter proj_ser_num with the version in mds_ when empty.\n",
    "## But this seems unnecessary since it's empty.\n",
    "for var in ['proj_num_spl_sfx_code', 'proj_ser_num']:\n",
    "    combined_data[var] = [m if pd.isna(k) else k for (m,k) in combined_data[['mds_'+var, var]].values]\n",
    "combined_data = combined_data.sort_values(by=['proj_ser_num', 'subproj_id', 'proj_num_spl_sfx_code', 'appl_id', 'hdp_id'])\n",
    "print(f\"Number of entries in merged dataset: {len(combined_data)}\")\n",
    "combined_data['proj_ser_num'].replace('', np.NaN, inplace=True)\n",
    "print(f\"Number of entries with empty proj_ser_num which will be dropped: {len(combined_data[pd.isna(combined_data.proj_ser_num)])}\")\n",
    "print(combined_data[pd.isna(combined_data.proj_ser_num)][['proj_ser_num', 'mds_proj_ser_num', 'hdp_id']])\n",
    "combined_data = combined_data[(~pd.isna(combined_data.proj_ser_num))]\n",
    "print(f\"*** Number of entries in merged dataset AFTER removing empty proj_ser_num: {len(combined_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     proj_ser_num  subproj_id proj_num_spl_sfx_code  xstudy_id_stewards  \\\n",
      "1264     AA021691         NaN                    S1                   0   \n",
      "1123     AA025480         NaN                    S1                   1   \n",
      "1243     AA025848         NaN                    S1                   2   \n",
      "1288     AG067493         NaN                   NaN                   3   \n",
      "248      AG067493         NaN                   NaN                   3   \n",
      "...           ...         ...                   ...                 ...   \n",
      "867      TR004701         NaN                   NaN                1209   \n",
      "944      TR004743         NaN                   NaN                1210   \n",
      "1105     TW007401         NaN                    S1                1211   \n",
      "1106     TW008163         NaN                    S1                1212   \n",
      "1107     TW009872         NaN                    S1                1213   \n",
      "\n",
      "      study_id  \n",
      "1264       0.0  \n",
      "1123       1.0  \n",
      "1243       2.0  \n",
      "1288       3.0  \n",
      "248        NaN  \n",
      "...        ...  \n",
      "867     1268.0  \n",
      "944     1269.0  \n",
      "1105    1270.0  \n",
      "1106    1271.0  \n",
      "1107    1272.0  \n",
      "\n",
      "[1617 rows x 5 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3440021678.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['proj_num_spl_sfx_code'].replace('', np.NaN, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3440021678.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  combined_data['subproj_id'].replace('', np.NaN, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "### Assign group numbers\n",
    "combined_data['proj_num_spl_sfx_code'].replace('', np.NaN, inplace=True)\n",
    "combined_data['subproj_id'].replace('', np.NaN, inplace=True)\n",
    "combined_data['xstudy_id_stewards'] = combined_data.groupby(by=['proj_ser_num', 'subproj_id', 'proj_num_spl_sfx_code'], dropna=False).ngroup()\n",
    "combined_data['study_id'] = combined_data.groupby(by=['xstudy_id_stewards', 'hdp_id']).ngroup()\n",
    "print(combined_data[ ['proj_ser_num', 'subproj_id', 'proj_num_spl_sfx_code', 'xstudy_id_stewards', 'study_id']])\n",
    "combined_data[ ['proj_ser_num', 'subproj_id', 'proj_num_spl_sfx_code', 'xstudy_id_stewards', 'study_id', 'hdp_id']].to_csv(input_dir/\"xstudy_id_stewards.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xstudy_id_stewards\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       4\n",
      "4       4\n",
      "       ..\n",
      "1209    1\n",
      "1210    1\n",
      "1211    1\n",
      "1212    1\n",
      "1213    1\n",
      "Length: 1214, dtype: int64\n",
      "5\n"
     ]
    }
   ],
   "source": [
    " ## Matched\n",
    " ### Make a dataset of xstudy_id_stewards and # of appl_ids\n",
    "xstud = combined_data[~pd.isna(combined_data['appl_id'])][ ['xstudy_id_stewards', 'appl_id']].copy(deep=True).drop_duplicates()\n",
    "xstud_count_applid = xstud.groupby('xstudy_id_stewards').size()\n",
    "print(xstud_count_applid)\n",
    "print(max(xstud_count_applid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xstudy_id_stewards\n",
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "1209    1\n",
      "1210    1\n",
      "1211    1\n",
      "1212    1\n",
      "1213    1\n",
      "Length: 1174, dtype: int64\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "## Match\n",
    "### Make a dataset of xstudy_id_stewards and # of hdpids\n",
    "xstud = combined_data[~pd.isna(combined_data['hdp_id'])][ ['xstudy_id_stewards', 'hdp_id']].copy(deep=True).drop_duplicates()\n",
    "xstud_count_hdpid = xstud.groupby('xstudy_id_stewards').size()\n",
    "print(xstud_count_hdpid)\n",
    "print(max(xstud_count_hdpid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine the two counts into the combined data column:\n",
    "combined_data['num_appl_by_xstudyidstewards'] = [xstud_count_applid[k] if k in xstud_count_applid else 0 for k in combined_data['xstudy_id_stewards']]\n",
    "combined_data['num_hdp_by_xstudyidstewards'] = [xstud_count_hdpid[k] if k in xstud_count_hdpid else 0 for k in combined_data['xstudy_id_stewards']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got valid rows: 1427\n",
      "Got valid rows: 1569\n",
      "Got valid rows: 1584\n",
      "INVALID rows: 33\n"
     ]
    }
   ],
   "source": [
    "combined_data['valid_flag'] = [1 if (n in [0,1]) else 0 for n in combined_data['num_hdp_by_xstudyidstewards']]\n",
    "### Question: These numbers look different\n",
    "print(f\"Got valid rows: {len(combined_data[combined_data['valid_flag']==1])}\") #1408\n",
    "combined_data['valid_flag'] = [1 if (v==0 and (na==nh and nha==1)) else v for (v, na, nh, nha) in combined_data[['valid_flag', 'num_appl_by_xstudyidstewards', 'num_hdp_by_xstudyidstewards', 'num_hdp_by_appl']].values]\n",
    "print(f\"Got valid rows: {len(combined_data[combined_data['valid_flag']==1])}\") #137\n",
    "combined_data['valid_flag'] = [1 if (v==0 and (na==1)) else v for (v, na) in combined_data[['valid_flag', 'num_appl_by_xstudyidstewards']].values]\n",
    "print(f\"Got valid rows: {len(combined_data[combined_data['valid_flag']==1])}\") #15\n",
    "\n",
    "print(f\"INVALID rows: {len(combined_data[combined_data['valid_flag']==0])}\") #33\n",
    "combined_data[combined_data['valid_flag']==0].to_csv(input_dir/\"sis_hdpid_comparison_issues.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data[['study_id', 'valid_flag', 'xstudy_id_stewards', 'num_appl_by_xstudyidstewards', 'num_hdp_by_xstudyidstewards', 'appl_id', 'hdp_id', 'proj_ser_num', 'subproj_id', 'proj_num_spl_sfx_code', 'proj_num']].to_csv(input_dir/\"full_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "1376\n",
      "142\n",
      "15\n"
     ]
    }
   ],
   "source": [
    "### START FILLING UP STUDY IDs\n",
    "\n",
    "hdpid0 = combined_data[ combined_data['num_hdp_by_xstudyidstewards'] == 0].copy(deep=True)\n",
    "print(len(hdpid0)) ##51 :: MATCH\n",
    "hdpid1 = combined_data[ combined_data['num_hdp_by_xstudyidstewards'] == 1].copy(deep=True)\n",
    "print(len(hdpid1)) ##1376: MATCH\n",
    "\n",
    "# When HDPID per stud_stewards is > 1::\n",
    "ss = combined_data[ ~combined_data['num_hdp_by_xstudyidstewards'].isin([0,1])]\n",
    "studyidgood1 = ss[ (ss['num_appl_by_xstudyidstewards']==ss['num_hdp_by_xstudyidstewards']) & (ss['num_hdp_by_appl']==1) ].copy(deep=True)\n",
    "print(len(studyidgood1)) # 142\n",
    "studyidgood2 = ss[ss['num_appl_by_xstudyidstewards']==1].copy(deep=True)\n",
    "print(len(studyidgood2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "### So far study_id has not been assigned to all the values, reassign:\n",
    "\n",
    "## HDPID0\n",
    "max_studyid = max(combined_data['study_id'])\n",
    "hdpid0['study_id'] = hdpid0.groupby(by=['xstudy_id_stewards']).ngroup() + max_studyid+1\n",
    "studyidgood3 = hdpid0\n",
    "\n",
    "## HDPID1\n",
    "hdpid1_ids = hdpid1[~pd.isna(hdpid1['study_id'])][ ['study_id', 'xstudy_id_stewards']].drop_duplicates().copy(deep=True)\n",
    "hdpid1_ids.rename(columns={'study_id':'new_study_id'}, inplace=True)\n",
    "hdpid1_merge = pd.merge(hdpid1, hdpid1_ids, how='left', on='xstudy_id_stewards')\n",
    "hdpid1_merge.drop(columns='study_id', inplace=True)\n",
    "hdpid1_merge.rename(columns={'new_study_id':'study_id'}, inplace=True)\n",
    "studyidgood4 = hdpid1_merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_studies = combined_data[ ~ (combined_data['num_hdp_by_xstudyidstewards'].isin([0,1]) |\n",
    "                                ((combined_data['num_appl_by_xstudyidstewards'] == combined_data['num_hdp_by_xstudyidstewards']) & (combined_data['num_hdp_by_appl']==1)) |\n",
    "                                (combined_data['num_appl_by_xstudyidstewards']==1)\n",
    "                                )\n",
    "                            ]\n",
    "rest_studies.to_csv(input_dir/\"valid_flag_0.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ctn studies: 17\n",
      "Non-CTN studies: 16\n",
      "10\n",
      "6\n",
      "      study_id  xstudy_id_stewards  num_appl_by_xstudyidstewards  \\\n",
      "888       62.0                  60                             4   \n",
      "1400      61.0                  60                             4   \n",
      "428      595.0                 550                             3   \n",
      "1495     594.0                 550                             3   \n",
      "442      600.0                 554                             3   \n",
      "1502     599.0                 554                             3   \n",
      "447      613.0                 565                             3   \n",
      "1506     612.0                 565                             3   \n",
      "433     1097.0                1043                             3   \n",
      "1496    1096.0                1043                             3   \n",
      "\n",
      "      num_hdp_by_xstudyidstewards   appl_id    hdp_id  \n",
      "888                             2  10705012  HDP01284  \n",
      "1400                            2   9898129  HDP00122  \n",
      "428                             2  10385311  HDP00455  \n",
      "1495                            2   9908597  HDP00123  \n",
      "442                             2  10390149  HDP00453  \n",
      "1502                            2   9910282  HDP00075  \n",
      "447                             2  10391263  HDP00447  \n",
      "1506                            2   9912141  HDP00240  \n",
      "433                             2  10386456  HDP00451  \n",
      "1496                            2   9908680  HDP00019  \n",
      "-----\n",
      "     study_id  xstudy_id_stewards  num_appl_by_xstudyidstewards  \\\n",
      "53        NaN                  60                             4   \n",
      "365       NaN                  60                             4   \n",
      "609       NaN                 550                             3   \n",
      "606       NaN                 554                             3   \n",
      "599       NaN                 565                             3   \n",
      "613       NaN                1043                             3   \n",
      "\n",
      "     num_hdp_by_xstudyidstewards   appl_id hdp_id  \n",
      "53                             2  10025169    NaN  \n",
      "365                            2  10375977    NaN  \n",
      "609                            2  10492608    NaN  \n",
      "606                            2  10491343    NaN  \n",
      "599                            2  10488729    NaN  \n",
      "613                            2  10493404    NaN  \n",
      "-----\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "ctn_studies = rest_studies[ [ ((not pd.isna(k)) and ('Clinical Trials Network' in k)) | ( ( not pd.isna(l)) and ('Clinical Trials Network' in l)) | (r == 'CTN') for (k,l,r) in rest_studies[['proj_title', 'res_prg', 'res_net']].values]]\n",
    "print(f\"Number of ctn studies: {len(ctn_studies)}\") # 17 (MATCH)\n",
    "\n",
    "nonctn_studies = rest_studies[ ~rest_studies['xstudy_id_stewards'].isin(ctn_studies['xstudy_id_stewards'])]\n",
    "print(f\"Non-CTN studies: {len(nonctn_studies)}\") # 16 :: Match\n",
    "\n",
    "nonctn_studies_hdp = nonctn_studies[ ~pd.isna(nonctn_studies['hdp_id'])].copy(deep=True)\n",
    "print(len(nonctn_studies_hdp)) #10 : Match\n",
    "\n",
    "nonctn_studies_nohdp = nonctn_studies[ pd.isna(nonctn_studies['hdp_id'])].copy(deep=True)\n",
    "print(len(nonctn_studies_nohdp)) #6 : Match\n",
    "\n",
    "## Try to get StudyID for NonCTN rows that do not have HDPID (and hence no studyid).\n",
    "## These seem to be matched by ACT Code per appl_id??\n",
    "merge = pd.merge(nonctn_studies_nohdp, nonctn_studies_hdp[['xstudy_id_stewards', 'act_code', 'study_id']], on='xstudy_id_stewards')\n",
    "\n",
    "print(nonctn_studies_hdp[['study_id', 'xstudy_id_stewards', 'num_appl_by_xstudyidstewards', 'num_hdp_by_xstudyidstewards', 'appl_id', 'hdp_id']])\n",
    "print(\"-----\")\n",
    "print(nonctn_studies_nohdp[['study_id', 'xstudy_id_stewards', 'num_appl_by_xstudyidstewards', 'num_hdp_by_xstudyidstewards', 'appl_id', 'hdp_id']])\n",
    "print(\"-----\")\n",
    "\n",
    "merge_match = merge[ merge['act_code_x'] == merge['act_code_y']].copy(deep=True)\n",
    "merge_match.rename(columns={'study_id_y': 'study_id', 'act_code_y':'act_code'}, inplace=True)\n",
    "nonctn_studies_nohdp = merge_match.drop(columns=['act_code_x', 'study_id_x'])\n",
    "print(len(nonctn_studies_nohdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1585\n"
     ]
    }
   ],
   "source": [
    "#### Creating the key of study_id and appl_id from all the datasets created above:\n",
    "keep_cols = ['study_id', 'appl_id']\n",
    "studyidkey = pd.concat([studyidgood1[keep_cols], studyidgood3[keep_cols], studyidgood4[keep_cols], nonctn_studies_nohdp[keep_cols], nonctn_studies_hdp[keep_cols]])\n",
    "\n",
    "print(len(studyidkey))\n",
    "studyidkey.rename(columns={'study_id' : 'xstudy_id'}, inplace=True)\n",
    "## Not using 15 from studyidgood2 because one appl_id is getting >1 HDPIDs.\n",
    "#### Match 1585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make sure that only one appl_id exists in the dataset\n",
    "max(studyidkey.groupby('appl_id').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "1617\n"
     ]
    }
   ],
   "source": [
    "# Add these studyids to the combined dataset:\n",
    "combined_data_studyid = pd.merge(combined_data, studyidkey, how='left', on='appl_id')\n",
    "print(len(combined_data_studyid[pd.isna(combined_data_studyid.xstudy_id)])) ## Unmatched: 17 CTN + 15 HDPID\n",
    "print(len(combined_data_studyid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "344\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "combined_data_studyid['study_id'] = [ x if not pd.isna(x) else s for (s,x) in combined_data_studyid[['study_id', 'xstudy_id']].values]\n",
    "print(len(combined_data[pd.isna(combined_data['study_id'])]))\n",
    "print(len(combined_data_studyid[pd.isna(combined_data_studyid['study_id'])]))\n",
    "## 339 study ids filled: Match!\n",
    "combined_data_studyid.drop(columns='xstudy_id', inplace=True)\n",
    "\n",
    "combined_data_studyid[['study_id', 'valid_flag', 'xstudy_id_stewards', 'num_appl_by_xstudyidstewards', 'num_hdp_by_xstudyidstewards', 'appl_id', 'hdp_id', 'proj_ser_num', 'subproj_id', 'proj_num_spl_sfx_code', 'proj_num']].to_csv(input_dir/\"full_data_studyid.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313\n",
      "1313\n",
      "Checking for any duplicates in the studyid: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/2212372781.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fiscyr_match['latest_bgt_end'] = [latest_bgt_end[k] if k in latest_bgt_end else np.NaN for k in data_fiscyr_match.study_id]\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/2212372781.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_fiscyr_match['match_bgt_end'] = [ (l==f) | (pd.isna(l) and pd.isna(f)) for (l,f) in data_fiscyr_match[['latest_bgt_end', 'bgt_end_date']].values]\n"
     ]
    }
   ],
   "source": [
    "#### Finding most recent appl_id for each study\n",
    "combined_data_studyid.sort_values(by=[\"study_id\", \"fisc_yr\"], inplace=True)\n",
    "\n",
    "for k in ['bgt_end', 'proj_end_date']:\n",
    "    combined_data_studyid[k+'_date'] = [  np.NaN if pd.isna(d) else ( np.NaN if str(d).startswith('0000') else datetime.strptime(str(d)[0:10], \"%Y-%m-%d\") ) for d in  combined_data_studyid[k]  ]\n",
    "\n",
    "latest_proj_end_dt_forstudy = combined_data_studyid.groupby('study_id')['proj_end_date_date'].max()\n",
    "combined_data_studyid['latest_proj_end_dt_forstudy'] = [latest_proj_end_dt_forstudy[k] if k in latest_proj_end_dt_forstudy else np.NaN for k in combined_data_studyid.study_id]\n",
    "latest_fy = combined_data_studyid.groupby('study_id')['fisc_yr'].max()\n",
    "combined_data_studyid['latest_fy'] = [latest_fy[k] if k in latest_fy else np.NaN for k in combined_data_studyid.study_id]\n",
    "combined_data_studyid['match_fy'] = [ (l==f) | (pd.isna(l) and pd.isna(f)) for (l,f) in combined_data_studyid[['latest_fy', 'fisc_yr']].values]\n",
    "\n",
    "data_fiscyr_match = combined_data_studyid[ combined_data_studyid['match_fy']]\n",
    "print(len(data_fiscyr_match))\n",
    "### QUESTION: 1312\n",
    "\n",
    "latest_bgt_end = data_fiscyr_match.groupby('study_id')['bgt_end_date'].max()\n",
    "data_fiscyr_match['latest_bgt_end'] = [latest_bgt_end[k] if k in latest_bgt_end else np.NaN for k in data_fiscyr_match.study_id]\n",
    "data_fiscyr_match['match_bgt_end'] = [ (l==f) | (pd.isna(l) and pd.isna(f)) for (l,f) in data_fiscyr_match[['latest_bgt_end', 'bgt_end_date']].values]\n",
    "data_fiscyr_bgtend_match = data_fiscyr_match[data_fiscyr_match['match_bgt_end']]\n",
    "print(len(data_fiscyr_bgtend_match))\n",
    "\n",
    "count_studyids = data_fiscyr_bgtend_match.groupby('study_id').size()\n",
    "print(f\"Checking for any duplicates in the studyid: {max(count_studyids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1313\n",
      "1273\n"
     ]
    }
   ],
   "source": [
    "recentapplid_key = data_fiscyr_bgtend_match[keep_cols].copy(deep=True)\n",
    "recentapplid_key.rename(columns={'appl_id':'study_most_recent_appl'}, inplace=True)\n",
    "print(len(recentapplid_key)) ## QUESTION: vs 1313\n",
    "recentapplid_key.columns\n",
    "\n",
    "hdpid_studyid_key = combined_data_studyid[['study_id', 'hdp_id', 'appl_id']].copy(deep=True)\n",
    "hdpid_studyid_key = hdpid_studyid_key[ ~(pd.isna(hdpid_studyid_key.study_id) | pd.isna(hdpid_studyid_key.hdp_id))]\n",
    "print(len(hdpid_studyid_key)) ##QUESTION: vs 1273 in \n",
    "hdpid_studyid_key.rename(columns={'appl_id':'study_hdp_id_appl', 'hdp_id':'study_hdp_id'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1612\n",
      "1612\n"
     ]
    }
   ],
   "source": [
    "#### Create the final lookup table:\n",
    "\n",
    "study_lookup_table = combined_data_studyid[~pd.isna(combined_data_studyid.study_id)][keep_cols].copy(deep=True)\n",
    "print(len(study_lookup_table))\n",
    "study_lookup_table = pd.merge(study_lookup_table, recentapplid_key, how='left', on='study_id' )\n",
    "study_lookup_table = pd.merge(study_lookup_table, hdpid_studyid_key, how='left', on='study_id' )\n",
    "study_lookup_table.drop_duplicates(inplace=True)\n",
    "print(len(study_lookup_table)) ## Question: 1588 vs 1607\n",
    "study_lookup_table.rename(columns={\"study_id\":\"xstudy_id\"}, inplace=True)\n",
    "study_lookup_table.columns\n",
    "study_lookup_table.to_csv(input_dir/\"study_lookup_table_gen.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lengths of the file generated: 1612\n",
      "Length of the dataset calculated in this notebook: 1612\n",
      "Max study id in the file generated: 1313\n",
      "Max study id in the dataset generated: 1312.0\n",
      "Comparing: appl_id\n",
      "Getting matches for: 1612\n",
      "Comparing: study_most_recent_appl\n",
      "Getting matches for: 1612\n",
      "Comparing: study_hdp_id\n",
      "Getting matches for: 1612\n",
      "Comparing: study_hdp_id_appl\n",
      "Getting matches for: 1612\n",
      "6\n",
      "882    HDP00885\n",
      "883    HDP00886\n",
      "879    HDP00882\n",
      "878    HDP00881\n",
      "880    HDP00883\n",
      "881    HDP00884\n",
      "Name: hdp_id, dtype: object\n",
      "6\n",
      "882    HDP00885\n",
      "883    HDP00886\n",
      "879    HDP00882\n",
      "878    HDP00881\n",
      "880    HDP00883\n",
      "881    HDP00884\n",
      "Name: hdp_id, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].fillna(-1, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].replace(\"-1\", np.NaN, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].fillna(-1, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].replace(\"-1\", np.NaN, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:17: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].fillna(-1, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/3229951474.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[appl_id_col].replace(\"-1\", np.NaN, inplace=True)\n",
      "/var/folders/tb/c_qhpk1j2jj3knzfnw72yj080000gq/T/ipykernel_78689/2225633290.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  gt_file['study_hdp_id_appl'].replace(\"0\", np.NaN, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "## Checking\n",
    "# Is Sabrina generated table the same that I generate here?\n",
    "gt_file = pd.read_csv(input_dir/\"study_lookup_table.csv\")\n",
    "convert_appl_ids_tostr(gt_file)\n",
    "convert_appl_ids_tostr(gt_file, 'study_most_recent_appl')\n",
    "convert_appl_ids_tostr(gt_file, 'study_hdp_id_appl')\n",
    "gt_file['study_hdp_id_appl'].replace(\"0\", np.NaN, inplace=True)\n",
    "\n",
    "\n",
    "print(f\"Lengths of the file generated: {len(gt_file)}\")\n",
    "print(f\"Length of the dataset calculated in this notebook: {len(study_lookup_table)}\")\n",
    "\n",
    "print(f\"Max study id in the file generated: {max(gt_file.xstudy_id)}\")\n",
    "print(f\"Max study id in the dataset generated: {max(study_lookup_table.xstudy_id)}\")\n",
    "\n",
    "gt_file.sort_values(by='appl_id', inplace=True)\n",
    "study_lookup_table.sort_values(by='appl_id', inplace=True)\n",
    "\n",
    "columns_to_match = ['appl_id', 'study_most_recent_appl', 'study_hdp_id', 'study_hdp_id_appl']\n",
    "a = gt_file[columns_to_match].rename( columns = {k: k+'_x' for k in columns_to_match}).sort_values(by=['appl_id_x', 'study_hdp_id_x']).reset_index(drop=True)\n",
    "b = study_lookup_table[columns_to_match].rename( columns = {k: k+'_y' for k in columns_to_match}).sort_values(by=['appl_id_y', 'study_hdp_id_y']).reset_index(drop=True)\n",
    "\n",
    "compare_dataset = pd.concat([a,b], axis=1)\n",
    "\n",
    "\n",
    "columns_to_match = ['appl_id', 'study_most_recent_appl', 'study_hdp_id', 'study_hdp_id_appl']\n",
    "\n",
    "for c in columns_to_match:\n",
    "    compare_dataset[c+'_check'] = [(x==y) | (pd.isna(x) & pd.isna(y)) for (x,y) in compare_dataset[[c+'_x', c+'_y']].values]\n",
    "    print(f\"Comparing: {c}\")\n",
    "    print(f\"Getting matches for: {len(compare_dataset[compare_dataset[c+'_check']])}\")\n",
    "compare_dataset['all_good'] = [ x & y & z & w for (x,y,z,w) in compare_dataset[ [k+'_check' for k in columns_to_match ]].values]\n",
    "compare_dataset.to_csv(input_dir/\"comparison.csv\")\n",
    "\n",
    "# Do ALL HDPIDs from platform's original table make into the table? If not - why?\n",
    "missing_hdps_fromprogress_tracker = progress_tracker_df[~progress_tracker_df['hdp_id'].isin(study_lookup_table.study_hdp_id)]['hdp_id'].drop_duplicates()\n",
    "print(len(missing_hdps_fromprogress_tracker))\n",
    "print(missing_hdps_fromprogress_tracker)\n",
    "missing_hdps_fromprogress_tracker = progress_tracker_df[~progress_tracker_df['hdp_id'].isin(gt_file.study_hdp_id)]['hdp_id'].drop_duplicates()\n",
    "print(len(missing_hdps_fromprogress_tracker))\n",
    "print(missing_hdps_fromprogress_tracker)\n",
    "\n",
    "# Can we keep track of projects that are not included because of formatting inconsistencies?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "## Looking at study_most_recent_appl, and seeing which were not matchd to platform\n",
    "unmatched = gt_file[pd.isna(gt_file.study_hdp_id)]\n",
    "print(len(unmatched))\n",
    "unmatched_most_recent = unmatched.study_most_recent_appl.drop_duplicates()\n",
    "print(len(unmatched_most_recent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appl_id</th>\n",
       "      <th>proj_num</th>\n",
       "      <th>proj_ser_num</th>\n",
       "      <th>proj_url</th>\n",
       "      <th>pi</th>\n",
       "      <th>awd_ty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>10022491</td>\n",
       "      <td>8R44NS119770-03</td>\n",
       "      <td>NS119770</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10022491</td>\n",
       "      <td>Pierre  Riviere</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>10029002</td>\n",
       "      <td>4R44DA046316-02</td>\n",
       "      <td>DA046316</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10029002</td>\n",
       "      <td>STUART J KAHN;JOHN A ZEBALA</td>\n",
       "      <td>4N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>10131167</td>\n",
       "      <td>5R34DA046635-03</td>\n",
       "      <td>DA046635</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10131167</td>\n",
       "      <td>JIAN  KONG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>10133699</td>\n",
       "      <td>5U24HD095254-04</td>\n",
       "      <td>HD095254</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10133699</td>\n",
       "      <td>Abhik  Das</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>10136565</td>\n",
       "      <td>5R01DA047094-03</td>\n",
       "      <td>DA047094</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10136565</td>\n",
       "      <td>Rajita  Sinha</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>10167785</td>\n",
       "      <td>5U01MH114087-05</td>\n",
       "      <td>MH114087</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10167785</td>\n",
       "      <td>Brian Kenneth Ahmedani;GREGORY E. SIMON</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>10186827</td>\n",
       "      <td>5U19MH113135-05</td>\n",
       "      <td>MH113135</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10186827</td>\n",
       "      <td>SPERO MARTIN MANSON</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>10197809</td>\n",
       "      <td>5U19MH121738-03</td>\n",
       "      <td>MH121738</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10197809</td>\n",
       "      <td>Beth E. Waitzfelder</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>10197811</td>\n",
       "      <td>5R01MH120124-03</td>\n",
       "      <td>MH120124</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10197811</td>\n",
       "      <td>Kara  Zivin</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>10217075</td>\n",
       "      <td>5U01DA046430-02</td>\n",
       "      <td>DA046430</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10217075</td>\n",
       "      <td>ADAM  BISAGA</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>10219462</td>\n",
       "      <td>4R33AT010606-03</td>\n",
       "      <td>AT010606</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10219462</td>\n",
       "      <td>Sean  Young</td>\n",
       "      <td>4N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>10246487</td>\n",
       "      <td>5R44AR074820-03</td>\n",
       "      <td>AR074820</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10246487</td>\n",
       "      <td>Owen B. McManus;Hongkang  Zhang</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253</th>\n",
       "      <td>10250564</td>\n",
       "      <td>5K01DA044279-04</td>\n",
       "      <td>DA044279</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10250564</td>\n",
       "      <td>Andria B Eisman</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>10268237</td>\n",
       "      <td>5R41DA053011-02</td>\n",
       "      <td>DA053011</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10268237</td>\n",
       "      <td>Donald Kim Shin</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>10269936</td>\n",
       "      <td>5U01DA051071-02</td>\n",
       "      <td>DA051071</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10269936</td>\n",
       "      <td>Paul T Bremer</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>10294238</td>\n",
       "      <td>5R01DA046532-04</td>\n",
       "      <td>DA046532</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10294238</td>\n",
       "      <td>DAVID Richard MAGUIRE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>10331849</td>\n",
       "      <td>5R01MH115840-04</td>\n",
       "      <td>MH115840</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10331849</td>\n",
       "      <td>Teresa  Brockie</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>10343721</td>\n",
       "      <td>5R01DA045695-04</td>\n",
       "      <td>DA045695</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10343721</td>\n",
       "      <td>Michael D Stein;RISA B WEISBERG</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>527</th>\n",
       "      <td>10460178</td>\n",
       "      <td>5UG1CA189824-09</td>\n",
       "      <td>CA189824</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10460178</td>\n",
       "      <td>GLENN J LESSER;Kathryn Elizabeth Weaver</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531</th>\n",
       "      <td>10467167</td>\n",
       "      <td>4R33DA056230-02</td>\n",
       "      <td>DA056230</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10467167</td>\n",
       "      <td>MARC  FISHMAN</td>\n",
       "      <td>4C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>10469599</td>\n",
       "      <td>5UH3AT009763-06</td>\n",
       "      <td>AT009763</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10469599</td>\n",
       "      <td>Julie M Fritz;Daniel  Rhon</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>10475213</td>\n",
       "      <td>5U01HL152401-04</td>\n",
       "      <td>HL152401</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10475213</td>\n",
       "      <td>RODNEY J.Y. HO</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>550</th>\n",
       "      <td>10475218</td>\n",
       "      <td>5U01HL152405-04</td>\n",
       "      <td>HL152405</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10475218</td>\n",
       "      <td>RICHARD C DUKE</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>10493291</td>\n",
       "      <td>5R42NS120548-03</td>\n",
       "      <td>NS120548</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10493291</td>\n",
       "      <td>Douglas Eric Brenneman;SARA J WARD</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>10532462</td>\n",
       "      <td>4R44AT011593-02</td>\n",
       "      <td>AT011593</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10532462</td>\n",
       "      <td>Jo  Masterson;Deanna  Waters</td>\n",
       "      <td>4N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>662</th>\n",
       "      <td>10569775</td>\n",
       "      <td>4R33AT010619-02</td>\n",
       "      <td>AT010619</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10569775</td>\n",
       "      <td>Alicia  Heapy</td>\n",
       "      <td>4N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>10583146</td>\n",
       "      <td>3UG1DA049436-04S3</td>\n",
       "      <td>DA049436</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10583146</td>\n",
       "      <td>JUDITH  FEINBERG;JANE M LIEBSCHUTZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>709</th>\n",
       "      <td>10588504</td>\n",
       "      <td>4R33DA057747-02</td>\n",
       "      <td>DA057747</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10588504</td>\n",
       "      <td>Jessica F Magidson</td>\n",
       "      <td>4C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>10589995</td>\n",
       "      <td>1U24TR004314-01</td>\n",
       "      <td>TR004314</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10589995</td>\n",
       "      <td>DANIEL K. BENJAMIN;Gordon R Bernard;Rachel Got...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>10619029</td>\n",
       "      <td>4UH3NS115108-02</td>\n",
       "      <td>NS115108</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10619029</td>\n",
       "      <td>Jiande  Chen</td>\n",
       "      <td>4N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>821</th>\n",
       "      <td>10646600</td>\n",
       "      <td>3UG1DA049436-04S4</td>\n",
       "      <td>DA049436</td>\n",
       "      <td>https://reporter.nih.gov/project-details/10646600</td>\n",
       "      <td>JUDITH  FEINBERG;JANE M LIEBSCHUTZ</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>991</th>\n",
       "      <td>9555046</td>\n",
       "      <td>5U2COD023375-03</td>\n",
       "      <td>OD023375</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9555046</td>\n",
       "      <td>DANIEL K. BENJAMIN;Laura Kristin NEWBY;Phillip...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>9775470</td>\n",
       "      <td>5R44TR001326-04</td>\n",
       "      <td>TR001326</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9775470</td>\n",
       "      <td>James J Hickman;MICHAEL L SHULER</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>9823898</td>\n",
       "      <td>5R01NS104295-03</td>\n",
       "      <td>NS104295</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9823898</td>\n",
       "      <td>Daniela M Menichella</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1164</th>\n",
       "      <td>9829976</td>\n",
       "      <td>5U10HD036801-22</td>\n",
       "      <td>HD036801</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9829976</td>\n",
       "      <td>Rebecca Gersnoviez Clifton</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1212</th>\n",
       "      <td>9850643</td>\n",
       "      <td>5R01NS045594-15</td>\n",
       "      <td>NS045594</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9850643</td>\n",
       "      <td>Jun-Ming  Zhang</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1338</th>\n",
       "      <td>9894780</td>\n",
       "      <td>5UG3DA048338-02</td>\n",
       "      <td>DA048338</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9894780</td>\n",
       "      <td>Jeffrey  Benner;Steven M Cohen</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1474</th>\n",
       "      <td>9912143</td>\n",
       "      <td>5R03DA046011-02</td>\n",
       "      <td>DA046011</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9912143</td>\n",
       "      <td>Padma  Gulur</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1514</th>\n",
       "      <td>9926864</td>\n",
       "      <td>5UG3DA048388-03</td>\n",
       "      <td>DA048388</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9926864</td>\n",
       "      <td>Richard  De La Garza;Edythe Danick London</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1538</th>\n",
       "      <td>9950853</td>\n",
       "      <td>5R01DE027454-03</td>\n",
       "      <td>DE027454</td>\n",
       "      <td>https://reporter.nih.gov/project-details/9950853</td>\n",
       "      <td>Yong  Chen</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       appl_id           proj_num proj_ser_num  \\\n",
       "46    10022491    8R44NS119770-03     NS119770   \n",
       "63    10029002    4R44DA046316-02     DA046316   \n",
       "102   10131167    5R34DA046635-03     DA046635   \n",
       "107   10133699    5U24HD095254-04     HD095254   \n",
       "110   10136565    5R01DA047094-03     DA047094   \n",
       "169   10167785    5U01MH114087-05     MH114087   \n",
       "197   10186827    5U19MH113135-05     MH113135   \n",
       "199   10197809    5U19MH121738-03     MH121738   \n",
       "200   10197811    5R01MH120124-03     MH120124   \n",
       "224   10217075    5U01DA046430-02     DA046430   \n",
       "228   10219462    4R33AT010606-03     AT010606   \n",
       "250   10246487    5R44AR074820-03     AR074820   \n",
       "253   10250564    5K01DA044279-04     DA044279   \n",
       "285   10268237    5R41DA053011-02     DA053011   \n",
       "286   10269936    5U01DA051071-02     DA051071   \n",
       "293   10294238    5R01DA046532-04     DA046532   \n",
       "316   10331849    5R01MH115840-04     MH115840   \n",
       "325   10343721    5R01DA045695-04     DA045695   \n",
       "527   10460178    5UG1CA189824-09     CA189824   \n",
       "531   10467167    4R33DA056230-02     DA056230   \n",
       "536   10469599    5UH3AT009763-06     AT009763   \n",
       "549   10475213    5U01HL152401-04     HL152401   \n",
       "550   10475218    5U01HL152405-04     HL152405   \n",
       "595   10493291    5R42NS120548-03     NS120548   \n",
       "640   10532462    4R44AT011593-02     AT011593   \n",
       "662   10569775    4R33AT010619-02     AT010619   \n",
       "699   10583146  3UG1DA049436-04S3     DA049436   \n",
       "709   10588504    4R33DA057747-02     DA057747   \n",
       "721   10589995    1U24TR004314-01     TR004314   \n",
       "804   10619029    4UH3NS115108-02     NS115108   \n",
       "821   10646600  3UG1DA049436-04S4     DA049436   \n",
       "991    9555046    5U2COD023375-03     OD023375   \n",
       "1110   9775470    5R44TR001326-04     TR001326   \n",
       "1152   9823898    5R01NS104295-03     NS104295   \n",
       "1164   9829976    5U10HD036801-22     HD036801   \n",
       "1212   9850643    5R01NS045594-15     NS045594   \n",
       "1338   9894780    5UG3DA048338-02     DA048338   \n",
       "1474   9912143    5R03DA046011-02     DA046011   \n",
       "1514   9926864    5UG3DA048388-03     DA048388   \n",
       "1538   9950853    5R01DE027454-03     DE027454   \n",
       "\n",
       "                                               proj_url  \\\n",
       "46    https://reporter.nih.gov/project-details/10022491   \n",
       "63    https://reporter.nih.gov/project-details/10029002   \n",
       "102   https://reporter.nih.gov/project-details/10131167   \n",
       "107   https://reporter.nih.gov/project-details/10133699   \n",
       "110   https://reporter.nih.gov/project-details/10136565   \n",
       "169   https://reporter.nih.gov/project-details/10167785   \n",
       "197   https://reporter.nih.gov/project-details/10186827   \n",
       "199   https://reporter.nih.gov/project-details/10197809   \n",
       "200   https://reporter.nih.gov/project-details/10197811   \n",
       "224   https://reporter.nih.gov/project-details/10217075   \n",
       "228   https://reporter.nih.gov/project-details/10219462   \n",
       "250   https://reporter.nih.gov/project-details/10246487   \n",
       "253   https://reporter.nih.gov/project-details/10250564   \n",
       "285   https://reporter.nih.gov/project-details/10268237   \n",
       "286   https://reporter.nih.gov/project-details/10269936   \n",
       "293   https://reporter.nih.gov/project-details/10294238   \n",
       "316   https://reporter.nih.gov/project-details/10331849   \n",
       "325   https://reporter.nih.gov/project-details/10343721   \n",
       "527   https://reporter.nih.gov/project-details/10460178   \n",
       "531   https://reporter.nih.gov/project-details/10467167   \n",
       "536   https://reporter.nih.gov/project-details/10469599   \n",
       "549   https://reporter.nih.gov/project-details/10475213   \n",
       "550   https://reporter.nih.gov/project-details/10475218   \n",
       "595   https://reporter.nih.gov/project-details/10493291   \n",
       "640   https://reporter.nih.gov/project-details/10532462   \n",
       "662   https://reporter.nih.gov/project-details/10569775   \n",
       "699   https://reporter.nih.gov/project-details/10583146   \n",
       "709   https://reporter.nih.gov/project-details/10588504   \n",
       "721   https://reporter.nih.gov/project-details/10589995   \n",
       "804   https://reporter.nih.gov/project-details/10619029   \n",
       "821   https://reporter.nih.gov/project-details/10646600   \n",
       "991    https://reporter.nih.gov/project-details/9555046   \n",
       "1110   https://reporter.nih.gov/project-details/9775470   \n",
       "1152   https://reporter.nih.gov/project-details/9823898   \n",
       "1164   https://reporter.nih.gov/project-details/9829976   \n",
       "1212   https://reporter.nih.gov/project-details/9850643   \n",
       "1338   https://reporter.nih.gov/project-details/9894780   \n",
       "1474   https://reporter.nih.gov/project-details/9912143   \n",
       "1514   https://reporter.nih.gov/project-details/9926864   \n",
       "1538   https://reporter.nih.gov/project-details/9950853   \n",
       "\n",
       "                                                     pi awd_ty  \n",
       "46                                      Pierre  Riviere      8  \n",
       "63                          STUART J KAHN;JOHN A ZEBALA     4N  \n",
       "102                                          JIAN  KONG      5  \n",
       "107                                          Abhik  Das      5  \n",
       "110                                       Rajita  Sinha      5  \n",
       "169             Brian Kenneth Ahmedani;GREGORY E. SIMON      5  \n",
       "197                                 SPERO MARTIN MANSON      5  \n",
       "199                                 Beth E. Waitzfelder      5  \n",
       "200                                         Kara  Zivin      5  \n",
       "224                                        ADAM  BISAGA      5  \n",
       "228                                         Sean  Young     4N  \n",
       "250                     Owen B. McManus;Hongkang  Zhang      5  \n",
       "253                                     Andria B Eisman      5  \n",
       "285                                     Donald Kim Shin      5  \n",
       "286                                       Paul T Bremer      5  \n",
       "293                               DAVID Richard MAGUIRE      5  \n",
       "316                                     Teresa  Brockie      5  \n",
       "325                     Michael D Stein;RISA B WEISBERG      5  \n",
       "527             GLENN J LESSER;Kathryn Elizabeth Weaver      5  \n",
       "531                                       MARC  FISHMAN     4C  \n",
       "536                          Julie M Fritz;Daniel  Rhon      5  \n",
       "549                                      RODNEY J.Y. HO      5  \n",
       "550                                      RICHARD C DUKE      5  \n",
       "595                  Douglas Eric Brenneman;SARA J WARD      5  \n",
       "640                        Jo  Masterson;Deanna  Waters     4N  \n",
       "662                                       Alicia  Heapy     4N  \n",
       "699                  JUDITH  FEINBERG;JANE M LIEBSCHUTZ      3  \n",
       "709                                  Jessica F Magidson     4C  \n",
       "721   DANIEL K. BENJAMIN;Gordon R Bernard;Rachel Got...      1  \n",
       "804                                        Jiande  Chen     4N  \n",
       "821                  JUDITH  FEINBERG;JANE M LIEBSCHUTZ      3  \n",
       "991   DANIEL K. BENJAMIN;Laura Kristin NEWBY;Phillip...      5  \n",
       "1110                   James J Hickman;MICHAEL L SHULER      5  \n",
       "1152                               Daniela M Menichella      5  \n",
       "1164                         Rebecca Gersnoviez Clifton      5  \n",
       "1212                                    Jun-Ming  Zhang      5  \n",
       "1338                     Jeffrey  Benner;Steven M Cohen      5  \n",
       "1474                                       Padma  Gulur      5  \n",
       "1514          Richard  De La Garza;Edythe Danick London      5  \n",
       "1538                                         Yong  Chen      5  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Is it in??\n",
    "reporter_df[reporter_df.appl_id.isin(unmatched_most_recent.values)][['appl_id', 'proj_num', 'proj_ser_num', 'proj_url', 'pi', 'awd_ty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appl_id</th>\n",
       "      <th>proj_num</th>\n",
       "      <th>proj_ser_num</th>\n",
       "      <th>pi</th>\n",
       "      <th>proj_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>10139426</td>\n",
       "      <td>3U01MH114087-04S1</td>\n",
       "      <td>MH114087</td>\n",
       "      <td>Brian Kenneth Ahmedani</td>\n",
       "      <td>Patient perspectives on clinical approaches to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>10167785</td>\n",
       "      <td>5U01MH114087-05</td>\n",
       "      <td>MH114087</td>\n",
       "      <td>Brian Kenneth Ahmedani;GREGORY E. SIMON</td>\n",
       "      <td>An Evaluation of the National Zero Suicide Mod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>9676620</td>\n",
       "      <td>3U01MH114087-02S2</td>\n",
       "      <td>MH114087</td>\n",
       "      <td>Brian Kenneth Ahmedani;GREGORY E. SIMON</td>\n",
       "      <td>Evaluating the Impact of Changes in Opioid Pre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       appl_id           proj_num proj_ser_num  \\\n",
       "114   10139426  3U01MH114087-04S1     MH114087   \n",
       "169   10167785    5U01MH114087-05     MH114087   \n",
       "1020   9676620  3U01MH114087-02S2     MH114087   \n",
       "\n",
       "                                           pi  \\\n",
       "114                    Brian Kenneth Ahmedani   \n",
       "169   Brian Kenneth Ahmedani;GREGORY E. SIMON   \n",
       "1020  Brian Kenneth Ahmedani;GREGORY E. SIMON   \n",
       "\n",
       "                                             proj_title  \n",
       "114   Patient perspectives on clinical approaches to...  \n",
       "169   An Evaluation of the National Zero Suicide Mod...  \n",
       "1020  Evaluating the Impact of Changes in Opioid Pre...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter_df[ reporter_df.proj_ser_num=='MH114087'][['appl_id', 'proj_num', 'proj_ser_num', 'pi', 'proj_title']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['proj_abs', 'act_code', 'ic_code', 'adm_ic', 'adm_ic_code', 'adm_ic_nm',\n",
       "       'fund_ic', 'ic_fund_code', 'ic_fund_yr', 'fund_ic_nm',\n",
       "       'fund_ic_tot_cst', 'appl_id', 'arra_fund', 'tot_fund', 'awd_not_date',\n",
       "       'awd_ty', 'bgt_end', 'bgt_strt', 'cfda_code', 'cong_dist', 'ctc_pi_nm',\n",
       "       'cr_pro_num', 'covid_res', 'amt_dir', 'fisc_yr', 'ful_foa',\n",
       "       'sty_sec_ful_grp_code', 'sty_sec_ful_nm', 'sty_sec_ful_des_code',\n",
       "       'sty_sec_ful_flex_code', 'sty_sec_ful_srg_code', 'sty_sec_ful_srg_flex',\n",
       "       'fund_mech', 'indct_cst_amt', 'is_act', 'is_new', 'mech_code_dc',\n",
       "       'org_dept_type', 'org_ext_id', 'org_cy', 'org_ctry', 'org_duns',\n",
       "       'org_fips', 'org_ipf_code', 'org_nm', 'org_st', 'org_zip_code',\n",
       "       'org_ty_code', 'org_ty_oth', 'org_ty_nm', 'phr_text', 'pref_terms',\n",
       "       'pi_fst_nm', 'pi', 'pi_is_ctc', 'pi_lst_nm', 'pi_mid_nm', 'pi_prof_id',\n",
       "       'pi_title', 'prg_ofc_fst_nm', 'prg_ofc', 'prg_ofc_lst_nm',\n",
       "       'prg_ofc_mid_nm', 'proj_url', 'projenddateCNV', 'proj_end_date',\n",
       "       'proj_num', 'proj_num_spl_act_code', 'proj_num_spl_ty_code',\n",
       "       'proj_nm_spl_supp_yr', 'proj_num_spl_ic_code', 'proj_ser_nm_spl',\n",
       "       'proj_num_spl_sfx_code', 'proj_nm_spl_yr', 'proj_ser_num',\n",
       "       'proj_strt_date', 'proj_title', 'spd_cat', 'spd_cat_[0]', 'subproj_id',\n",
       "       'trms'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reporter_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
